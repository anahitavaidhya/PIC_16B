<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Anahita Vaidhya">
<meta name="dcterms.date" content="2025-03-05">

<title>Text Classification – Python for Beginners</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-6bd9cfa162949bde0a231f530c97869d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Python for Beginners</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../posts/HW1_InteractiveGraphics/"> 
<span class="menu-text">Data Visualization</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../posts/HW2_Scrapy/"> 
<span class="menu-text">Web Scraping</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../posts/HW3_WebDevelopment/"> 
<span class="menu-text">Web Development</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../posts/HW4_HeatDiffusion/"> 
<span class="menu-text">Heat Diffusion</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../posts/HW5_ImageClassification/"> 
<span class="menu-text">Image Classification</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../posts/HW6_TextClassification/"> 
<span class="menu-text">Text Classification</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About Anahita</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Text Classification</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">About</div>
                <div class="quarto-category">Welcome</div>
                <div class="quarto-category">HW0_PenguinVisualization</div>
                <div class="quarto-category">HW1_InteractiveGraphics</div>
                <div class="quarto-category">HW2_Scrapy</div>
                <div class="quarto-category">HW3_WebDevelopment</div>
                <div class="quarto-category">HW4_HeatDiffusion</div>
                <div class="quarto-category">HW5_ImageClassification</div>
                <div class="quarto-category">HW6_TextClassification</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Anahita Vaidhya </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">March 5, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="fake-it-til-you-make-it-exposing-fake-news-with-ai" class="level1">
<h1><strong>Fake It ’til You Make It: Exposing Fake News with AI</strong></h1>
<p>Hello again! Welcome to the last blog post of our Python for Beginners series! Today, we will be using Text Classification to help solve one of the most pressing challenges of the digital age — fake news.</p>
<p>Misinformation from fake news spreads like wildfire, shaping public opinion and even influencing democratic processes along the way.</p>
<p><em>But can we use AI to help us fight back?</em></p>
<p>In this post, we’ll build and evaluate a fake news classifier using Keras, using text classification to determine whether a news article is real or not.</p>
<p>Our dataset comes from research by Ahmed, Traore, and Saad (2017), who explored fake news detection using N-Gram Analysis and Machine Learning. We’ll take their findings a step further by using deep learning to train models that analyze article titles, full text, or both.</p>
<p>Let’s get started and see if AI can separate fact from fiction!</p>
<section id="set-up-project" class="level2">
<h2 class="anchored" data-anchor-id="set-up-project">Set Up Project</h2>
<p>Before we dive into building our fake news classifier, let’s start by importing all the necessary libraries. These will help us with everything from data processing to model training and evaluation.</p>
<div id="cell-3" class="cell" data-outputid="11af6315-8aa7-4bba-b8b0-22e42593dc3e">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import libraries</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> keras</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> string</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> utils</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> layers</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.express <span class="im">as</span> px</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> stopwords</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow_datasets <span class="im">as</span> tfds</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize <span class="im">import</span> word_tokenize</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.models <span class="im">import</span> Model</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> Input, TextVectorization, Embedding, Dense, Dropout, GlobalAveragePooling1D, Concatenate</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'stopwords'</span>)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'punkt'</span>)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>stop_words <span class="op">=</span> <span class="bu">set</span>(stopwords.words(<span class="st">'english'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[nltk_data] Downloading package stopwords to /root/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package punkt to /root/nltk_data...
[nltk_data]   Package punkt is already up-to-date!</code></pre>
</div>
</div>
</section>
<section id="step-1-acquiring-training-data" class="level2">
<h2 class="anchored" data-anchor-id="step-1-acquiring-training-data">Step 1: Acquiring Training Data</h2>
<p>Now that we have set up our environment, it’s time to load in our data! Our dataset can be accessed in two easy ways:</p>
<ol type="1">
<li>Read it directly into Python using pd.read_csv()</li>
<li>Download it to your computer and load it from disk</li>
</ol>
<p>To keep it simple, let’s go with the first approach:</p>
<div id="cell-5" class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># URL to the dataset</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>train_url <span class="op">=</span> <span class="st">"https://raw.githubusercontent.com/pic16b-ucla/25W/refs/heads/main/datasets/fake_news_train.csv"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-6" class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Pandas version of dataset</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(train_url)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s take a quick peek to see what our data looks like:</p>
<div id="cell-8" class="cell" data-outputid="7c5dad8c-c245-4d57-c537-76df9938e4ce">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize dataset</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>data.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">

  <div id="df-6ef8df8e-81c3-4e12-95c7-a612dda43831" class="colab-df-container">
    <div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Unnamed: 0</th>
<th data-quarto-table-cell-role="th">title</th>
<th data-quarto-table-cell-role="th">text</th>
<th data-quarto-table-cell-role="th">fake</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>17366</td>
<td>Merkel: Strong result for Austria's FPO 'big c...</td>
<td>German Chancellor Angela Merkel said on Monday...</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>5634</td>
<td>Trump says Pence will lead voter fraud panel</td>
<td>WEST PALM BEACH, Fla.President Donald Trump sa...</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>17487</td>
<td>JUST IN: SUSPECTED LEAKER and “Close Confidant...</td>
<td>On December 5, 2017, Circa s Sara Carter warne...</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>12217</td>
<td>Thyssenkrupp has offered help to Argentina ove...</td>
<td>Germany s Thyssenkrupp, has offered assistance...</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>5535</td>
<td>Trump say appeals court decision on travel ban...</td>
<td>President Donald Trump on Thursday called the ...</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-6ef8df8e-81c3-4e12-95c7-a612dda43831')" title="Convert this dataframe to an interactive table." style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-6ef8df8e-81c3-4e12-95c7-a612dda43831 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-6ef8df8e-81c3-4e12-95c7-a612dda43831');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-58c06b58-97c0-4b36-8ed5-59b5cfa89c74">
  <button class="colab-df-quickchart" onclick="quickchart('df-58c06b58-97c0-4b36-8ed5-59b5cfa89c74')" title="Suggest charts" style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"></path>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-58c06b58-97c0-4b36-8ed5-59b5cfa89c74 button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>

    </div>
  </div>
</div>
</div>
<p>This dataset is structured as follows:</p>
<ul>
<li><strong>title</strong> – The headline of the article.</li>
<li><strong>text</strong> – The full body of the article.</li>
<li><strong>fake</strong> – A binary label:
<ul>
<li>0 → The article is real.</li>
<li>1 → The article is fake.</li>
</ul></li>
</ul>
</section>
<section id="step-2-make-dataset-function" class="level2">
<h2 class="anchored" data-anchor-id="step-2-make-dataset-function">Step 2: Make Dataset Function</h2>
<p>Before we can train our model, we have to first prepare our dataset. We will clean and transform the raw text data into a format that TensorFlow can process efficiently. To do this, we create a function called make_dataset that preprocesses our data:</p>
<ol type="1">
<li><strong>Text Cleaning</strong> – The function first standardizes the text by converting it to lowercase, and filtering out stopwords (common words like ‘the’, ‘and’, ‘but’, that don’t add meaning).</li>
<li><strong>Dataset Construction</strong> – It then converts the processed data into a tf.data.Dataset, with each sample consisting of two inputs: the title and the article text, and one output: the fake news label (0 for real news, 1 for fake news).</li>
<li><strong>Batching for Efficiency</strong> – Finally, the dataset is shuffled and batched to improve training speed. A batch size of 100 is used to balance performance and accuracy.</li>
</ol>
<p>Here is how to implement the function:</p>
<div id="cell-11" class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make Dataset Function</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> make_dataset(url):</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Read dataset to Pandas</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>  df <span class="op">=</span> pd.read_csv(url)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Make title and text lowercase</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>  df[<span class="st">"title"</span>] <span class="op">=</span> df[<span class="st">"title"</span>].<span class="bu">str</span>.lower()</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>  df[<span class="st">"text"</span>] <span class="op">=</span> df[<span class="st">"text"</span>].<span class="bu">str</span>.lower()</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># df column names</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>  df.columns <span class="op">=</span> [<span class="st">"Unnamed: 0"</span>, <span class="st">"title"</span>, <span class="st">"text"</span>, <span class="st">"fake"</span>]</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Remove stopwords in title and text</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>  df[<span class="st">'title'</span>] <span class="op">=</span> df[<span class="st">'title'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="st">' '</span>.join([word <span class="cf">for</span> word <span class="kw">in</span> x.split() <span class="cf">if</span> word <span class="kw">not</span> <span class="kw">in</span> (stop_words)]))</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>  df[<span class="st">'text'</span>] <span class="op">=</span> df[<span class="st">'text'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="st">' '</span>.join([word <span class="cf">for</span> word <span class="kw">in</span> x.split() <span class="cf">if</span> word <span class="kw">not</span> <span class="kw">in</span> (stop_words)]))</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Get inputs (title, text) and output (fake label)</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>  titles <span class="op">=</span> df[<span class="st">'title'</span>].values</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>  texts <span class="op">=</span> df[<span class="st">'text'</span>].values</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>  labels <span class="op">=</span> df[<span class="st">'fake'</span>].values.astype(np.int32)</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Create a Dataset</span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>  dataset <span class="op">=</span> tf.data.Dataset.from_tensor_slices(((titles, texts), labels))</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>  dataset <span class="op">=</span> dataset.batch(<span class="dv">100</span>).prefetch(tf.data.experimental.AUTOTUNE)</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Return</span></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> dataset</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-12" class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Dataset</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> make_dataset(train_url)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="step-3-split-data-for-validation" class="level2">
<h2 class="anchored" data-anchor-id="step-3-split-data-for-validation">Step 3: Split Data for Validation</h2>
<p>To make sure our model generalizes well to unseen data, we need to split our dataset into training (80%) and validation (20%) sets. The training set is used to optimize the model, while the validation set helps us evaluate performance and detect overfitting.</p>
<p><strong>Steps:</strong> 1. <strong>Count the Total Samples</strong> – Since tf.data.Dataset does not have a built-in len() function, we use the reduce() method to iterate through the dataset and count its elements. 2. <strong>Determine Split Sizes</strong> – We calculate 80% of the total dataset size for training, which leaves 20% for validation. 3. <strong>Use take() and skip()</strong> – We use .take(train_size) to get the first 80% of the dataset for training and .skip(train_size) to get the remaining 20% for validation.</p>
<p>Here’s the implementation:</p>
<div id="cell-14" class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the dataset into training (80%) and validation (20%)</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Count total elements in dataset</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>dataset_size <span class="op">=</span> data.<span class="bu">reduce</span>(<span class="dv">0</span>, <span class="kw">lambda</span> x, _: x <span class="op">+</span> <span class="dv">1</span>).numpy()</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Define split sizes</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>train_size <span class="op">=</span> <span class="bu">int</span>(<span class="fl">0.8</span> <span class="op">*</span> dataset_size)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Split dataset</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Take first 80% of the dataset</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>train_ds <span class="op">=</span> data.take(train_size)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Skip first 80% and take remaining 20%</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>val_ds <span class="op">=</span> data.skip(train_size)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="step-4-base-rate" class="level2">
<h2 class="anchored" data-anchor-id="step-4-base-rate">Step 4: Base Rate</h2>
<p>Another step before training our model is to determine the base rate accuracy — the accuracy a model would achieve by always predicting the most frequent class. This gives us a benchmark to compare our trained model against.</p>
<p><strong>Steps:</strong></p>
<ol type="1">
<li><strong>Extract Labels</strong> – Since our dataset is in tf.data.Dataset format, we need to extract the labels using .unbatch() and .map().</li>
<li><strong>Count the Labels</strong> – We count how many articles are labeled as true (0) and how many are labeled as fake (1).</li>
<li><strong>Calculate Baseline Accuracy</strong> – The base rate is the proportion of the majority class in the dataset.</li>
</ol>
<div id="cell-16" class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Labels iterator</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>labels_iterator <span class="op">=</span> train_ds.unbatch().<span class="bu">map</span>(<span class="kw">lambda</span> inputs, label: label).as_numpy_iterator()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-17" class="cell" data-outputid="6fe3e6d5-532d-4caf-ece4-f0afafad7f0a">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Examine labels</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> np.array(<span class="bu">list</span>(labels_iterator))</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Count true and false</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>num_true <span class="op">=</span> np.<span class="bu">sum</span>(labels <span class="op">==</span> <span class="dv">0</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>num_false <span class="op">=</span> np.<span class="bu">sum</span>(labels <span class="op">==</span> <span class="dv">1</span>)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Print</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of True Articles: </span><span class="sc">{</span>num_true<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of False Articles: </span><span class="sc">{</span>num_false<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of True Articles: 8603
Number of False Articles: 9397</code></pre>
</div>
</div>
<div id="cell-18" class="cell" data-outputid="e77c4ea1-f6af-4c59-b27f-11cd2c8b241e">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Baseline Accuracy</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>total <span class="op">=</span> num_true <span class="op">+</span> num_false</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>baseline <span class="op">=</span> (<span class="bu">max</span>(num_true, num_false) <span class="op">/</span> total) <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Baseline accuracy: </span><span class="sc">{</span>baseline<span class="sc">:.2f}</span><span class="ss">%"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Baseline accuracy: 52.21%</code></pre>
</div>
</div>
</section>
<section id="step-5-creating-models" class="level2">
<h2 class="anchored" data-anchor-id="step-5-creating-models">Step 5: Creating Models</h2>
<p>Now, it’s time to get to the good stuff! In natural language processing (NLP), the way we preprocess and encode textual data impacts model performance. To build our fake news detection model, we have multiple inputs, such as titles and text. Usually, these inputs are processed separately, but a shared vectorization and embedding layer makes sure our models are consistent (same words have the same vector representation in title and text) and efficient (eliminates redundance embedding layers to reduce memory usage and model complexity).</p>
<p>We will implement a shared vectorization and embedding layer to power three different models:</p>
<ol type="1">
<li><p>Title-Only Model</p></li>
<li><p>Text-Only Model</p></li>
<li><p>Combined Title + Text Model</p></li>
</ol>
<p>Here is the implementation:</p>
<div id="cell-20" class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Preparing a shared text vectorization layer for tf model</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>size_vocabulary <span class="op">=</span> <span class="dv">2000</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardization function</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> standardization(input_data):</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    lowercase <span class="op">=</span> tf.strings.lower(input_data)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    no_punctuation <span class="op">=</span> tf.strings.regex_replace(lowercase, <span class="st">'[</span><span class="sc">%s</span><span class="st">]'</span> <span class="op">%</span> re.escape(string.punctuation), <span class="st">''</span>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> no_punctuation</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Shared Text Vectorization Layer</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>shared_vectorize_layer <span class="op">=</span> layers.TextVectorization(</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>                                                  standardize<span class="op">=</span>standardization,</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>                                                  max_tokens<span class="op">=</span>size_vocabulary,</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>                                                  output_mode<span class="op">=</span><span class="st">'int'</span>,</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>                                                  output_sequence_length<span class="op">=</span><span class="dv">500</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>                                                 )</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Access both title and text</span></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>shared_vectorize_layer.adapt(train_ds.<span class="bu">map</span>(<span class="kw">lambda</span> x, y: tf.concat([x[<span class="dv">0</span>], x[<span class="dv">1</span>]], axis<span class="op">=</span><span class="dv">0</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-21" class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Shared Embedding Layer</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>shared_embedding <span class="op">=</span> layers.Embedding(input_dim<span class="op">=</span>size_vocabulary, output_dim<span class="op">=</span><span class="dv">16</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here, shared_vectorize_layer tokenizes and converts input text into numerical sequences, while shared_embedding_layer maps these sequences into dense vector representations.</p>
<section id="title-only-model" class="level3">
<h3 class="anchored" data-anchor-id="title-only-model">Title-Only Model</h3>
<div id="cell-24" class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Functional API for Title Model</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Title Input Layer</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>title_input <span class="op">=</span> keras.Input(shape<span class="op">=</span>(<span class="dv">1</span>,), dtype<span class="op">=</span>tf.string, name<span class="op">=</span><span class="st">"title_input"</span>)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Shared vectorization and embedding layers</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>title_vectors <span class="op">=</span> shared_vectorize_layer(title_input)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>title_embeddings <span class="op">=</span> shared_embedding(title_vectors)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Rest of the layers</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Converts sequence into a single vector</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> layers.GlobalAveragePooling1D()(title_embeddings)</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> layers.Dense(<span class="dv">32</span>, activation<span class="op">=</span><span class="st">"relu"</span>)(x)</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> layers.Dropout(<span class="fl">0.2</span>)(x)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Output layer</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Binary classification</span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>output <span class="op">=</span> layers.Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">"sigmoid"</span>)(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-25" class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the model</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>title_model <span class="op">=</span> keras.Model(inputs<span class="op">=</span>title_input, outputs<span class="op">=</span>output, name<span class="op">=</span><span class="st">"Title_Only_Model"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-26" class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compile the model</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>title_model.<span class="bu">compile</span>(</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    loss<span class="op">=</span><span class="st">"binary_crossentropy"</span>,</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    optimizer<span class="op">=</span><span class="st">"adam"</span>,</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    metrics<span class="op">=</span>[<span class="st">"accuracy"</span>]</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-27" class="cell" data-outputid="ead08b86-9d4a-4c77-feda-8609f9a2458a">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the Model</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> title_model.fit(</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extract title and label</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    train_ds.<span class="bu">map</span>(<span class="kw">lambda</span> x, y: (x[<span class="dv">0</span>], y)),</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extract title and label</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    validation_data<span class="op">=</span>val_ds.<span class="bu">map</span>(<span class="kw">lambda</span> x, y: (x[<span class="dv">0</span>], y)),</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">100</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 12ms/step - accuracy: 0.5145 - loss: 0.6925 - val_accuracy: 0.5266 - val_loss: 0.6908
Epoch 2/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 2s 11ms/step - accuracy: 0.5357 - loss: 0.6899 - val_accuracy: 0.7341 - val_loss: 0.6796
Epoch 3/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 2s 10ms/step - accuracy: 0.6034 - loss: 0.6693 - val_accuracy: 0.7620 - val_loss: 0.6087
Epoch 4/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 3s 16ms/step - accuracy: 0.6937 - loss: 0.5981 - val_accuracy: 0.7732 - val_loss: 0.5148
Epoch 5/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 10ms/step - accuracy: 0.7486 - loss: 0.5207 - val_accuracy: 0.7946 - val_loss: 0.4619
Epoch 6/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 2s 10ms/step - accuracy: 0.7621 - loss: 0.4876 - val_accuracy: 0.8038 - val_loss: 0.4303
Epoch 7/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 2s 10ms/step - accuracy: 0.7840 - loss: 0.4535 - val_accuracy: 0.8197 - val_loss: 0.4069
Epoch 8/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 3s 14ms/step - accuracy: 0.8038 - loss: 0.4213 - val_accuracy: 0.8296 - val_loss: 0.3875
Epoch 9/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 2s 12ms/step - accuracy: 0.8075 - loss: 0.4140 - val_accuracy: 0.8370 - val_loss: 0.3677
Epoch 10/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 2s 10ms/step - accuracy: 0.8175 - loss: 0.3960 - val_accuracy: 0.8496 - val_loss: 0.3479
Epoch 11/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 3s 10ms/step - accuracy: 0.8335 - loss: 0.3696 - val_accuracy: 0.8521 - val_loss: 0.3354
Epoch 12/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 3s 10ms/step - accuracy: 0.8394 - loss: 0.3590 - val_accuracy: 0.8535 - val_loss: 0.3226
Epoch 13/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 2s 13ms/step - accuracy: 0.8496 - loss: 0.3385 - val_accuracy: 0.8735 - val_loss: 0.3024
Epoch 14/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 2s 12ms/step - accuracy: 0.8556 - loss: 0.3256 - val_accuracy: 0.8753 - val_loss: 0.2905
Epoch 15/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 2s 10ms/step - accuracy: 0.8663 - loss: 0.3069 - val_accuracy: 0.8764 - val_loss: 0.2824
Epoch 16/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 2s 10ms/step - accuracy: 0.8740 - loss: 0.2924 - val_accuracy: 0.8714 - val_loss: 0.2846
Epoch 17/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 2s 10ms/step - accuracy: 0.8749 - loss: 0.2875 - val_accuracy: 0.8708 - val_loss: 0.2804
Epoch 18/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 3s 10ms/step - accuracy: 0.8775 - loss: 0.2816 - val_accuracy: 0.8998 - val_loss: 0.2482
Epoch 19/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 3s 15ms/step - accuracy: 0.8829 - loss: 0.2722 - val_accuracy: 0.8973 - val_loss: 0.2459
Epoch 20/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 10ms/step - accuracy: 0.8891 - loss: 0.2575 - val_accuracy: 0.9007 - val_loss: 0.2384</code></pre>
</div>
</div>
<section id="validation-accuracy-for-title-only-model" class="level4">
<h4 class="anchored" data-anchor-id="validation-accuracy-for-title-only-model">Validation Accuracy for Title-Only Model</h4>
<div id="cell-29" class="cell" data-outputid="8560aeb0-5201-4148-f53a-460020c81a34">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate model</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>val_loss, val_acc <span class="op">=</span> title_model.evaluate(val_ds.<span class="bu">map</span>(<span class="kw">lambda</span> x, y: (x[<span class="dv">0</span>], y)))</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Validation Accuracy: </span><span class="sc">{</span>val_acc<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>45/45 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.9026 - loss: 0.2368
Validation Accuracy: 0.90</code></pre>
</div>
</div>
</section>
<section id="visualizations" class="level4">
<h4 class="anchored" data-anchor-id="visualizations">Visualizations</h4>
<p>We will create a function that we can use for the rest of the models to plot Training and Validation Accuracy/Loss to keep track of how our models do throughout the epochs.</p>
<div id="cell-31" class="cell" data-outputid="54b40df3-7705-4b67-b3cd-859f618f0798">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create figure</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">4</span>))</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Training vs. Validation Accuracy</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">1</span>)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"accuracy"</span>], label <span class="op">=</span> <span class="st">"Training"</span>)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"val_accuracy"</span>], label <span class="op">=</span> <span class="st">"Validation"</span>)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>plt.gca().<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="st">"Epoch"</span>, ylabel <span class="op">=</span> <span class="st">"Accuracy"</span>)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Title-Only Model: Training vs. Validation Accuracy"</span>)</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Training vs. Validation Loss</span></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">2</span>)</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"loss"</span>], label <span class="op">=</span> <span class="st">"Training"</span>)</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"val_loss"</span>], label <span class="op">=</span> <span class="st">"Validation"</span>)</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>plt.gca().<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="st">"Epoch"</span>, ylabel <span class="op">=</span> <span class="st">"Loss"</span>)</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Title-Only Model: Training vs. Validation Loss"</span>)</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Show</span></span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-19-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-32" class="cell" data-outputid="968143ee-7f74-4dc9-fbef-bf01df1227d8">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualization for title model</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>utils.plot_model(title_model, <span class="st">"title_visualization.png"</span>,</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>                       show_shapes<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>                       show_layer_names<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-20-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="analysis" class="level4">
<h4 class="anchored" data-anchor-id="analysis">Analysis</h4>
<p>The title-only model achieving 90% validation accuracy is quite impressive, considering the fact that it is only using the title of the article. This suggests that the title alone must contain a lot of important information for distinguishing between real vs.&nbsp;fake news. The model is effectively capturing key features from just a short, high-level summary of the content, which is a positive indicator of the model’s ability to generalize from minimal information.</p>
</section>
</section>
<section id="text-only-model" class="level3">
<h3 class="anchored" data-anchor-id="text-only-model">Text-Only Model</h3>
<div id="cell-35" class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Functional API for Text Model</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Text Input Layer</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>text_input <span class="op">=</span> keras.Input(shape<span class="op">=</span>(<span class="dv">1</span>,), dtype<span class="op">=</span>tf.string, name<span class="op">=</span><span class="st">"text_input"</span>)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Shared vectorization and embedding layers</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>text_vectors <span class="op">=</span> shared_vectorize_layer(text_input)</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>text_embeddings <span class="op">=</span> shared_embedding(text_vectors)</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Rest of the layers</span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Converts sequence into a single vector</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> layers.GlobalAveragePooling1D()(text_embeddings)</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> layers.Dense(<span class="dv">32</span>, activation<span class="op">=</span><span class="st">"relu"</span>)(x)</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> layers.Dropout(<span class="fl">0.2</span>)(x)</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Output layer</span></span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>output <span class="op">=</span> layers.Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">"sigmoid"</span>)(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-36" class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the model</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>text_model <span class="op">=</span> keras.Model(inputs<span class="op">=</span>text_input, outputs<span class="op">=</span>output, name<span class="op">=</span><span class="st">"Text_Only_Model"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-37" class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compile the model</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>text_model.<span class="bu">compile</span>(</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>    loss<span class="op">=</span><span class="st">"binary_crossentropy"</span>,</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>    optimizer<span class="op">=</span><span class="st">"adam"</span>,</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>    metrics<span class="op">=</span>[<span class="st">"accuracy"</span>]</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-38" class="cell" data-outputid="ea41f600-95f9-43b0-f838-d39cca2bb7a1">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the Model</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> text_model.fit(</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>    train_ds.<span class="bu">map</span>(<span class="kw">lambda</span> x, y: (x[<span class="dv">1</span>], y)), <span class="co"># Extract text and label</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    validation_data<span class="op">=</span>val_ds.<span class="bu">map</span>(<span class="kw">lambda</span> x, y: (x[<span class="dv">1</span>], y)), <span class="co"># Extract text and label</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">20</span>,  <span class="co"># Adjust epochs based on overfitting</span></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">100</span></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 6s 24ms/step - accuracy: 0.6196 - loss: 0.6552 - val_accuracy: 0.8546 - val_loss: 0.4592
Epoch 2/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 18ms/step - accuracy: 0.8534 - loss: 0.4076 - val_accuracy: 0.8887 - val_loss: 0.2883
Epoch 3/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 6s 23ms/step - accuracy: 0.9047 - loss: 0.2692 - val_accuracy: 0.9310 - val_loss: 0.2111
Epoch 4/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 28ms/step - accuracy: 0.9288 - loss: 0.2141 - val_accuracy: 0.9562 - val_loss: 0.1735
Epoch 5/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 3s 19ms/step - accuracy: 0.9405 - loss: 0.1852 - val_accuracy: 0.9616 - val_loss: 0.1502
Epoch 6/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 26ms/step - accuracy: 0.9486 - loss: 0.1616 - val_accuracy: 0.9622 - val_loss: 0.1378
Epoch 7/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 18ms/step - accuracy: 0.9497 - loss: 0.1484 - val_accuracy: 0.9658 - val_loss: 0.1237
Epoch 8/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 18ms/step - accuracy: 0.9554 - loss: 0.1360 - val_accuracy: 0.9622 - val_loss: 0.1193
Epoch 9/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 20ms/step - accuracy: 0.9563 - loss: 0.1270 - val_accuracy: 0.9694 - val_loss: 0.1072
Epoch 10/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 3s 18ms/step - accuracy: 0.9607 - loss: 0.1166 - val_accuracy: 0.9703 - val_loss: 0.1013
Epoch 11/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 6s 24ms/step - accuracy: 0.9664 - loss: 0.1084 - val_accuracy: 0.9717 - val_loss: 0.0974
Epoch 12/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 18ms/step - accuracy: 0.9664 - loss: 0.1034 - val_accuracy: 0.9726 - val_loss: 0.0929
Epoch 13/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 18ms/step - accuracy: 0.9686 - loss: 0.0978 - val_accuracy: 0.9712 - val_loss: 0.0899
Epoch 14/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 6s 21ms/step - accuracy: 0.9691 - loss: 0.0926 - val_accuracy: 0.9726 - val_loss: 0.0859
Epoch 15/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 3s 18ms/step - accuracy: 0.9717 - loss: 0.0884 - val_accuracy: 0.9733 - val_loss: 0.0833
Epoch 16/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 6s 24ms/step - accuracy: 0.9730 - loss: 0.0840 - val_accuracy: 0.9733 - val_loss: 0.0815
Epoch 17/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 18ms/step - accuracy: 0.9749 - loss: 0.0794 - val_accuracy: 0.9744 - val_loss: 0.0802
Epoch 18/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 19ms/step - accuracy: 0.9764 - loss: 0.0756 - val_accuracy: 0.9751 - val_loss: 0.0774
Epoch 19/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 6s 21ms/step - accuracy: 0.9771 - loss: 0.0710 - val_accuracy: 0.9753 - val_loss: 0.0753
Epoch 20/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 3s 18ms/step - accuracy: 0.9775 - loss: 0.0681 - val_accuracy: 0.9742 - val_loss: 0.0751</code></pre>
</div>
</div>
<section id="validation-accuracy-for-text-only-model" class="level4">
<h4 class="anchored" data-anchor-id="validation-accuracy-for-text-only-model">Validation Accuracy for Text-Only Model</h4>
<div id="cell-40" class="cell" data-outputid="c3a3ad73-2b82-4697-cbbe-cc1e16c6694c">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate model</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>val_loss, val_acc <span class="op">=</span> text_model.evaluate(val_ds.<span class="bu">map</span>(<span class="kw">lambda</span> x, y: (x[<span class="dv">1</span>], y)))</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Validation Accuracy: </span><span class="sc">{</span>val_acc<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>45/45 ━━━━━━━━━━━━━━━━━━━━ 1s 16ms/step - accuracy: 0.9777 - loss: 0.0740
Validation Accuracy: 0.97</code></pre>
</div>
</div>
</section>
<section id="visualizations-1" class="level4">
<h4 class="anchored" data-anchor-id="visualizations-1">Visualizations</h4>
<div id="cell-42" class="cell" data-outputid="f61295fa-af3a-4317-d485-9fc49658a515">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create figure</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">4</span>))</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Training vs. Validation Accuracy</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">1</span>)</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"accuracy"</span>], label <span class="op">=</span> <span class="st">"Training"</span>)</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"val_accuracy"</span>], label <span class="op">=</span> <span class="st">"Validation"</span>)</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>plt.gca().<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="st">"Epoch"</span>, ylabel <span class="op">=</span> <span class="st">"Accuracy"</span>)</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Text-Only Model: Training vs. Validation Accuracy"</span>)</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Training vs. Validation Loss</span></span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">2</span>)</span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"loss"</span>], label <span class="op">=</span> <span class="st">"Training"</span>)</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"val_loss"</span>], label <span class="op">=</span> <span class="st">"Validation"</span>)</span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a>plt.gca().<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="st">"Epoch"</span>, ylabel <span class="op">=</span> <span class="st">"Loss"</span>)</span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Text-Only Model: Training vs. Validation Loss"</span>)</span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Show</span></span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-26-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-43" class="cell" data-outputid="810ac69e-74bd-4984-9eb6-e4c445c21e95">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualization for title model</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>utils.plot_model(text_model, <span class="st">"text_visualization.png"</span>,</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>                       show_shapes<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>                       show_layer_names<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-27-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="analysis-1" class="level4">
<h4 class="anchored" data-anchor-id="analysis-1">Analysis</h4>
<p>The text-only model achieving a 97% validation accuracy is a sizable improvement over the title-only model’s 90%. This suggests that the full text provides more valuable information for distinguishing between classes like real vs.&nbsp;fake news compared to just the title. The increase in accuracy means that the body of the text contains additional context, details, and subtle cues that the model can use to make more informed predictions.</p>
</section>
</section>
<section id="combined-title-text-model" class="level3">
<h3 class="anchored" data-anchor-id="combined-title-text-model">Combined Title + Text Model</h3>
<div id="cell-46" class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Title Input</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>title_input <span class="op">=</span> keras.Input(shape<span class="op">=</span>(<span class="dv">1</span>,), dtype<span class="op">=</span>tf.string, name<span class="op">=</span><span class="st">"title_input"</span>)</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>title_vectors <span class="op">=</span> shared_vectorize_layer(title_input)</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>title_embeddings <span class="op">=</span> shared_embedding(title_vectors)</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>title_output <span class="op">=</span> layers.GlobalAveragePooling1D()(title_embeddings)</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Text Input</span></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>text_input <span class="op">=</span> keras.Input(shape<span class="op">=</span>(<span class="dv">1</span>,), dtype<span class="op">=</span>tf.string, name<span class="op">=</span><span class="st">"text_input"</span>)</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>text_vectors <span class="op">=</span> shared_vectorize_layer(text_input)</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>text_embeddings <span class="op">=</span> shared_embedding(text_vectors)</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>text_output <span class="op">=</span> layers.GlobalAveragePooling1D()(text_embeddings)</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Combinining inputs</span></span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a>merged <span class="op">=</span> layers.concatenate([title_output, text_output])</span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Fully connected layers</span></span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> layers.Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">"relu"</span>)(merged)</span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> layers.Dropout(<span class="fl">0.2</span>)(x)</span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> layers.Dense(<span class="dv">32</span>, activation<span class="op">=</span><span class="st">"relu"</span>)(x)</span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> layers.Dropout(<span class="fl">0.2</span>)(x)</span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Output Layer</span></span>
<span id="cb34-23"><a href="#cb34-23" aria-hidden="true" tabindex="-1"></a>final_output <span class="op">=</span> layers.Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">"sigmoid"</span>)(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-47" class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the model</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>combined_model <span class="op">=</span> keras.Model(inputs<span class="op">=</span>[title_input, text_input], outputs<span class="op">=</span>final_output, name<span class="op">=</span><span class="st">"Title_Text_Model"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-48" class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compile Model</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>combined_model.<span class="bu">compile</span>(</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>    loss<span class="op">=</span><span class="st">"binary_crossentropy"</span>,</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>    optimizer<span class="op">=</span><span class="st">"adam"</span>,</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>    metrics<span class="op">=</span>[<span class="st">"accuracy"</span>]</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-49" class="cell" data-outputid="10885a12-de79-4115-c578-a3047d9e8e00">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train Model</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> combined_model.fit(</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get title, text, and labels</span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>    train_ds.<span class="bu">map</span>(<span class="kw">lambda</span> x, y: ((x[<span class="dv">0</span>], x[<span class="dv">1</span>]), y)),</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get title, text, and labels</span></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>    validation_data<span class="op">=</span>val_ds.<span class="bu">map</span>(<span class="kw">lambda</span> x, y: ((x[<span class="dv">0</span>], x[<span class="dv">1</span>]), y)),</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">100</span></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 8s 31ms/step - accuracy: 0.7980 - loss: 0.4460 - val_accuracy: 0.9634 - val_loss: 0.1102
Epoch 2/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 9s 25ms/step - accuracy: 0.9672 - loss: 0.1036 - val_accuracy: 0.9616 - val_loss: 0.1036
Epoch 3/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 6s 32ms/step - accuracy: 0.9703 - loss: 0.0873 - val_accuracy: 0.9676 - val_loss: 0.0893
Epoch 4/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 26ms/step - accuracy: 0.9803 - loss: 0.0649 - val_accuracy: 0.9742 - val_loss: 0.0736
Epoch 5/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 31ms/step - accuracy: 0.9823 - loss: 0.0571 - val_accuracy: 0.9652 - val_loss: 0.0936
Epoch 6/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 9s 25ms/step - accuracy: 0.9817 - loss: 0.0545 - val_accuracy: 0.9753 - val_loss: 0.0707
Epoch 7/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 7s 40ms/step - accuracy: 0.9863 - loss: 0.0467 - val_accuracy: 0.9762 - val_loss: 0.0659
Epoch 8/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 6s 33ms/step - accuracy: 0.9860 - loss: 0.0423 - val_accuracy: 0.9836 - val_loss: 0.0548
Epoch 9/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 30ms/step - accuracy: 0.9872 - loss: 0.0392 - val_accuracy: 0.9827 - val_loss: 0.0567
Epoch 10/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 25ms/step - accuracy: 0.9854 - loss: 0.0412 - val_accuracy: 0.9665 - val_loss: 0.0922
Epoch 11/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 6s 33ms/step - accuracy: 0.9874 - loss: 0.0385 - val_accuracy: 0.9748 - val_loss: 0.0717
Epoch 12/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 27ms/step - accuracy: 0.9849 - loss: 0.0417 - val_accuracy: 0.9861 - val_loss: 0.0494
Epoch 13/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 26ms/step - accuracy: 0.9910 - loss: 0.0277 - val_accuracy: 0.9845 - val_loss: 0.0515
Epoch 14/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 6s 31ms/step - accuracy: 0.9911 - loss: 0.0270 - val_accuracy: 0.9836 - val_loss: 0.0576
Epoch 15/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 26ms/step - accuracy: 0.9919 - loss: 0.0262 - val_accuracy: 0.9854 - val_loss: 0.0517
Epoch 16/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 6s 32ms/step - accuracy: 0.9935 - loss: 0.0215 - val_accuracy: 0.9847 - val_loss: 0.0541
Epoch 17/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 26ms/step - accuracy: 0.9932 - loss: 0.0223 - val_accuracy: 0.9834 - val_loss: 0.0547
Epoch 18/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 4s 25ms/step - accuracy: 0.9932 - loss: 0.0233 - val_accuracy: 0.9766 - val_loss: 0.0727
Epoch 19/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 6s 32ms/step - accuracy: 0.9909 - loss: 0.0256 - val_accuracy: 0.9843 - val_loss: 0.0562
Epoch 20/20
180/180 ━━━━━━━━━━━━━━━━━━━━ 5s 26ms/step - accuracy: 0.9934 - loss: 0.0219 - val_accuracy: 0.9840 - val_loss: 0.0565</code></pre>
</div>
</div>
<section id="validation-accuracy-for-title-text-model" class="level4">
<h4 class="anchored" data-anchor-id="validation-accuracy-for-title-text-model">Validation Accuracy for Title + Text Model</h4>
<div id="cell-51" class="cell" data-outputid="f31f8f86-16d8-4f9a-892e-a4dd13cc1b61">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>val_loss, val_acc <span class="op">=</span> combined_model.evaluate(</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>    val_ds.<span class="bu">map</span>(<span class="kw">lambda</span> x, y: ((x[<span class="dv">0</span>], x[<span class="dv">1</span>]), y))</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Print Validation Accuracy</span></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Validation Accuracy: </span><span class="sc">{</span>val_acc<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>45/45 ━━━━━━━━━━━━━━━━━━━━ 1s 14ms/step - accuracy: 0.9872 - loss: 0.0561
Validation Accuracy: 0.98</code></pre>
</div>
</div>
</section>
<section id="visualizations-2" class="level4">
<h4 class="anchored" data-anchor-id="visualizations-2">Visualizations</h4>
<div id="cell-53" class="cell" data-outputid="5865cca0-06b8-4c94-c6a5-e0fa13be9a66">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create figure</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">4</span>))</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Training vs. Validation Accuracy</span></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">1</span>)</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"accuracy"</span>], label <span class="op">=</span> <span class="st">"Training"</span>)</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"val_accuracy"</span>], label <span class="op">=</span> <span class="st">"Validation"</span>)</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>plt.gca().<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="st">"Epoch"</span>, ylabel <span class="op">=</span> <span class="st">"Accuracy"</span>)</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Combined Model: Training vs. Validation Accuracy"</span>)</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Training vs. Validation Loss</span></span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">2</span>)</span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"loss"</span>], label <span class="op">=</span> <span class="st">"Training"</span>)</span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">"val_loss"</span>], label <span class="op">=</span> <span class="st">"Validation"</span>)</span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a>plt.gca().<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="st">"Epoch"</span>, ylabel <span class="op">=</span> <span class="st">"Loss"</span>)</span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Combined Model: Training vs. Validation Loss"</span>)</span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-20"><a href="#cb41-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Show</span></span>
<span id="cb41-21"><a href="#cb41-21" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-33-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-54" class="cell" data-outputid="8d9b382b-b9f7-44a9-dddb-0071abb74d1b">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualization for title model</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>utils.plot_model(combined_model, <span class="st">"combined_visualization.png"</span>,</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>                       show_shapes<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>                       show_layer_names<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-34-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="analysis-2" class="level4">
<h4 class="anchored" data-anchor-id="analysis-2">Analysis</h4>
<p>The combined model achieving a 98% validation accuracy shows an improvement of 8% over the title-only model, but only a 1% improvement over the text-only model. This suggests that while combining the title and the full text provides some added value, the majority of the performance boost likely comes from the full text itself.</p>
<p>The large jump from the title-only model to the combined model reflects how the title can still contribute useful information, even though it may not be as rich as the full article. The fact that the improvement over the text-only model is only 1% implies that the full text already captures most of the necessary features for accurate classification, and adding the title does not introduce much additional useful information.</p>
</section>
</section>
</section>
<section id="step-6-evaluating-model-performance-on-unseen-data" class="level2">
<h2 class="anchored" data-anchor-id="step-6-evaluating-model-performance-on-unseen-data">Step 6: Evaluating Model Performance on Unseen Data</h2>
<p>Now that we’ve fine-tuned our model and optimized its performance on validation data, it’s time for the ultimate test: unseen data. Evaluating our best model on fresh, unencountered samples will help us see how well our model generalizes beyond the training set.</p>
<section id="test-data" class="level4">
<h4 class="anchored" data-anchor-id="test-data">Test Data</h4>
<div id="cell-58" class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>test_url <span class="op">=</span> <span class="st">"https://raw.githubusercontent.com/pic16b-ucla/25W/refs/heads/main/datasets/fake_news_test.csv"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To have consistent results, we’ll preprocess this data using the same make_dataset function we defined earlier. This will standardize formatting, tokenize the text appropriately, and prepare it for evaluation.</p>
<div id="cell-60" class="cell">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Dataset</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>test_data <span class="op">=</span> make_dataset(test_url)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="evaluate-the-model" class="level4">
<h4 class="anchored" data-anchor-id="evaluate-the-model">Evaluate the Model</h4>
<div id="cell-62" class="cell" data-outputid="843d439f-e94e-46b0-fe31-aa99b1a04a3c">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>test_loss, test_accuracy <span class="op">=</span> combined_model.evaluate(test_data)</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Test Accuracy: </span><span class="sc">{</span>test_accuracy<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Test Loss: </span><span class="sc">{</span>test_loss<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model on validation data</span></span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>val_loss, val_accuracy <span class="op">=</span> combined_model.evaluate(val_ds)</span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Validation Accuracy: </span><span class="sc">{</span>val_accuracy<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Validation Loss: </span><span class="sc">{</span>val_loss<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>225/225 ━━━━━━━━━━━━━━━━━━━━ 3s 11ms/step - accuracy: 0.9842 - loss: 0.0576
Test Accuracy: 0.9833
Test Loss: 0.0595
45/45 ━━━━━━━━━━━━━━━━━━━━ 1s 11ms/step - accuracy: 0.9872 - loss: 0.0561
Validation Accuracy: 0.9840
Validation Loss: 0.0565</code></pre>
</div>
</div>
<div id="cell-63" class="cell">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>weights <span class="op">=</span> combined_model.get_layer(<span class="st">'embedding'</span>).get_weights()[<span class="dv">0</span>] <span class="co"># get the weights from the embedding layer</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>vocab <span class="op">=</span> shared_vectorize_layer.get_vocabulary()                <span class="co"># get the vocabulary from our data prep for later</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-64" class="cell">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>weights <span class="op">=</span> combined_model.get_layer(<span class="st">'embedding'</span>).get_weights()[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-65" class="cell" data-outputid="1a88ca51-22b1-44ac-9379-321bd8afaefd">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(weights.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(2000, 16)</code></pre>
</div>
</div>
<div id="cell-66" class="cell">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>weights <span class="op">=</span> pca.fit_transform(weights)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-67" class="cell" data-outputid="be0ed992-085d-400a-c869-0959c4d2f223">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>weights.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="57">
<pre><code>(2000, 2)</code></pre>
</div>
</div>
<div id="cell-68" class="cell" data-outputid="b3f99da7-bcc3-4254-edfc-9e3212c8374a">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>embedding_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">'word'</span> : vocab,</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'x0'</span>   : weights[:,<span class="dv">0</span>],</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'x1'</span>   : weights[:,<span class="dv">1</span>]</span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>embedding_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="58">

  <div id="df-22be851f-58d7-4b95-928e-8e7e495c7c98" class="colab-df-container">
    <div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">word</th>
<th data-quarto-table-cell-role="th">x0</th>
<th data-quarto-table-cell-role="th">x1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td></td>
<td>0.458991</td>
<td>-0.369868</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>[UNK]</td>
<td>-3.254118</td>
<td>3.480346</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>said</td>
<td>11.903173</td>
<td>7.233503</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>trump</td>
<td>-7.662038</td>
<td>3.243038</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>us</td>
<td>13.215361</td>
<td>-7.409301</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1995</td>
<td>reaction</td>
<td>-4.046322</td>
<td>-2.003912</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1996</td>
<td>ministers</td>
<td>3.829593</td>
<td>-2.292025</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1997</td>
<td>wonder</td>
<td>-6.529799</td>
<td>-4.318990</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1998</td>
<td>setting</td>
<td>-0.664706</td>
<td>0.334590</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1999</td>
<td>sector</td>
<td>1.703211</td>
<td>0.525156</td>
</tr>
</tbody>
</table>

<p>2000 rows × 3 columns</p>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-22be851f-58d7-4b95-928e-8e7e495c7c98')" title="Convert this dataframe to an interactive table." style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-22be851f-58d7-4b95-928e-8e7e495c7c98 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-22be851f-58d7-4b95-928e-8e7e495c7c98');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-899be2e2-e1c4-42e4-af74-50dd7209b008">
  <button class="colab-df-quickchart" onclick="quickchart('df-899be2e2-e1c4-42e4-af74-50dd7209b008')" title="Suggest charts" style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"></path>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-899be2e2-e1c4-42e4-af74-50dd7209b008 button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>

  <div id="id_e4b47f23-eba2-4fdd-9c55-5ad4bf4bb038">
    <style>
      .colab-df-generate {
        background-color: #E8F0FE;
        border: none;
        border-radius: 50%;
        cursor: pointer;
        display: none;
        fill: #1967D2;
        height: 32px;
        padding: 0 0 0 0;
        width: 32px;
      }

      .colab-df-generate:hover {
        background-color: #E2EBFA;
        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
        fill: #174EA6;
      }

      [theme=dark] .colab-df-generate {
        background-color: #3B4455;
        fill: #D2E3FC;
      }

      [theme=dark] .colab-df-generate:hover {
        background-color: #434B5C;
        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
        fill: #FFFFFF;
      }
    </style>
    <button class="colab-df-generate" onclick="generateWithVariable('embedding_df')" title="Generate code using this dataframe." style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <path d="M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z"></path>
  </svg>
    </button>
    <script>
      (() => {
      const buttonEl =
        document.querySelector('#id_e4b47f23-eba2-4fdd-9c55-5ad4bf4bb038 button.colab-df-generate');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      buttonEl.onclick = () => {
        google.colab.notebook.generateWithVariable('embedding_df');
      }
      })();
    </script>
  </div>

    </div>
  </div>
</div>
</div>
<div id="cell-69" class="cell" data-outputid="326005c0-6a91-45d4-b258-cff786bac879">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> px.scatter(embedding_df,</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>                 x <span class="op">=</span> <span class="st">"x0"</span>,</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>                 y <span class="op">=</span> <span class="st">"x1"</span>,</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>                 size <span class="op">=</span> <span class="bu">list</span>(np.ones(<span class="bu">len</span>(embedding_df))),</span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>                 size_max <span class="op">=</span> <span class="dv">3</span>,</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>                 hover_name <span class="op">=</span> <span class="st">"word"</span>)</span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a>fig.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<meta charset="utf-8">

    <div>            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script><script type="text/javascript">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}</script>                <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script charset="utf-8" src="https://cdn.plot.ly/plotly-2.35.2.min.js"></script>                <div id="50c21bcc-b241-4957-91ef-fd66dca627b3" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("50c21bcc-b241-4957-91ef-fd66dca627b3")) {                    Plotly.newPlot(                        "50c21bcc-b241-4957-91ef-fd66dca627b3",                        [{"hovertemplate":"\u003cb\u003e%{hovertext}\u003c\u002fb\u003e\u003cbr\u003e\u003cbr\u003ex0=%{x}\u003cbr\u003ex1=%{y}\u003cbr\u003esize=%{marker.size}\u003cextra\u003e\u003c\u002fextra\u003e","hovertext":["","[UNK]","said","trump","us","would","president","people","one","new","state","also","house","donald","clinton","states","government","obama","republican","could","told","united","white","like","campaign","news","election","two","last","time","first","party","hillary","former","even","year","country","years","many","security","may","media","political","say","make","police","court","get","national","republicans","made","law","since","american","going","bill","presidential","back","russia","percent","says","north","senate","democratic","administration","support","it","america","vote","trumps","know","week","think","including","public","way","group","take","officials","according","office","federal","foreign","called","tax","million","right","military","world","statement","department","saying","want","washington","see","russian","congress","well","tuesday","still","much","minister","another","women","day","democrats","part","wednesday","work","go","thursday","policy","friday","asked","war","china","2016","deal","rights","black","next","americans","monday","committee","help","need","secretary","korea","city","official","video","general","three","leader","never","case","whether","man","york","show","senator","order","report","around","meeting","fbi","come","members","good","candidate","use","took","attack","left","intelligence","power","without","times","really","countries","syria","end","put","used","top","that","every","twitter","money","trade","plan","investigation","justice","decision","month","leaders","iran","change","family","business","fact","nuclear","long","information","reported","groups","already","conservative","fox","south","days","interview","voters","international","story","speech","far","chief","several","call","must","health","director","got","children","likely","place","move","clear","months","issue","something","social","believe","agency","program","however","among","school","press","john","home","barack","sanders","immigration","least","muslim","watch","major","border","islamic","control","might","things","recent","trying","came","found","killed","reporters","great","supporters","post","number","act","actually","seen","this","billion","matter","him","give","though","earlier","point","democrat","spokesman","sunday","yet","big","win","march","look","attacks","working","thing","system","talks","keep","today","economic","free","later","went","nation","making","eu","the","real","little","away","set","executive","violence","legal","become","defense","stop","let","them","ever","member","senior","four","past","nothing","forces","companies","prime","comment","opposition","sanctions","lawmakers","cruz","gun","added","illegal","july","issues","european","un","nations","taking","governor","january","woman","head","held","better","action","following","known","across","continue","job","gop","human","person","company","local","care","2015","supreme","expected","force","high","community","given","now","possible","wall","process","judge","response","team","men","legislation","pay","financial","enough","others","ban","released","source","refugees","attorney","nominee","syrian","important","june","night","reports","wants","lot","union","history","evidence","done","wrote","face","run","open","close","fight","course","1","taken","mexico","plans","question","majority","special","email","anyone","life","air","budget","using","ryan","conference","private","staff","debate","putin","crisis","20","10","behind","i","find","best","comments","race","second","iraq","anything","ago","university","despite","november","less","death","future","lives","accused","saudi","role","early","agreement","calling","efforts","mr","able","instead","visit","someone","sources","saturday","along","israel","five","letter","comes","lead","full","service","jobs","weeks","students","name","within","region","hard","council","sure","economy","current","announced","paul","coalition","getting","civil","live","emails","texas","britain","rules","ties","running","citizens","global","muslims","liberal","event","due","calls","october","young","elections","congressional","obamacare","facebook","comey","sent","line","healthcare","effort","climate","allow","december","chairman","coming","claims","reform","center","candidates","problem","votes","thousands","ruling","needs","nearly","position","is","8","leave","weapons","tell","florida","middle","daily","street","army","hold","wanted","racist","peace","authorities","politics","talk","makes","representatives","september","rule","2014","bad","led","2","latest","turkey","meet","relations","out","outside","15","message","criminal","east","parliament","officers","list","germany","start","here","gave","bush","poll","failed","sexual","immediately","april","capital","february","everyone","words","began","together","conservatives","late","based","agencies","access","whose","central","cannot","you","questions","tried","reason","thought","means","lost","there","rally","threat","cut","workers","fake","immigrants","voting","charges","george","ahead","bring","protect","speaking","hope","2017","services","read","showed","different","concerns","rather","elected","strong","energy","try","stand","six","we","millions","spending","policies","planned","decided","shooting","ministry","laws","key","always","idea","fire","missile","organization","almost","august","allies","recently","3","room","enforcement","again","shows","hate","tweet","host","happened","everything","allowed","release","parties","industry","allegations","involved","denied","received","oil","entire","old","met","freedom","talking","market","district","often","morning","funding","provide","side","presidency","situation","seems","officer","30","shot","fighting","myanmar","europe","agreed","large","bank","12","nomination","looking","kind","needed","james","century","west","near","up","especially","vice","include","travel","small","arrested","california","chinese","step","personal","hit","actions","hearing","tillerson","claim","cases","data","potential","and","representative","j","insurance","terrorist","adding","british","fired","movement","biggest","korean","interest","foundation","voted","request","worked","realdonaldtrump","adviser","clearly","protesters","address","western","true","either","wrong","feel","alleged","wife","moscow","confirmed","details","return","5","hours","term","water","spoke","forward","all","leading","although","documents","polls","aid","board","pressure","decades","serious","front","11","area","review","2012","truth","building","county","relationship","father","terrorism","me","college","german","bernie","crime","claimed","commission","david","nov","in","merkel","families","love","victory","points","declined","appeared","record","forced","25","goes","passed","mccain","main","dollars","influence","paid","mean","son","4","toward","soon","brought","taxes","continued","ted","more","independence","simply","protest","mike","signed","probably","network","lawyer","so","gets","debt","food","result","short","started","mark","sign","turn","arabia","agenda","primary","mayor","turned","rubio","pretty","push","pass","leadership","raised","popular","became","attempt","michael","posted","speaker","religious","longer","spent","previously","view","whole","giving","friends","deputy","pence","included","guy","proposed","half","article","saw","final","seeking","issued","ambassador","child","level","created","total","violent","phone","regional","obamas","conflict","secret","2013","discuss","protests","japan","independent","incident","sessions","speak","remarks","refugee","clintons","ask","living","firm","respond","town","hand","fund","fear","website","hundreds","absolutely","mass","changes","brexit","21st","criticized","armed","account","telling","no","flynn","helped","education","described","tv","areas","increase","flag","else","currently","robert","example","constitution","third","voter","similar","remain","not","inside","employees","heard","largest","convention","risk","experts","reality","hands","repeatedly","programs","spokeswoman","appears","18","medical","photo","san","published","victims","seek","panel","lower","rate","johnson","nato","focus","asking","warned","senators","takes","page","tweeted","criticism","form","understand","schools","isis","apparently","transition","mainstream","iraqi","reporter","cia","100","funds","king","crowd","single","seven","militants","safety","proposal","cost","rohingya","individuals","completely","al","24","cause","research","carolina","stay","build","student","christian","opinion","trip","northern","politicians","do","happen","businesses","problems","threats","france","share","measures","dangerous","online","television","interests","fellow","prevent","powerful","book","respect","joe","quickly","development","troops","previous","concern","charged","6","fraud","13","presidentelect","parents","16","ready","project","internet","land","exactly","radio","huge","drug","committed","french","southern","on","served","poor","target","provided","assault","urged","safe","create","base","results","coverage","cuts","concerned","answer","numbers","attention","consider","responsible","presidents","ground","false","kurdish","events","terrorists","certainly","church","yes","corruption","choice","residents","considered","island","rep","moment","hear","leaving","named","holding","charge","14","tweets","repeal","terror","operations","measure","died","chance","mcconnell","her","knew","sean","responded","critical","a","organizations","filed","dnc","kelly","governments","50","society","class","series","certain","9","diplomatic","worst","prison","virginia","radical","sides","investment","eight","rhetoric","expressed","send","favor","ensure","democracy","agree","terms","scandal","paris","low","dead","moore","knows","complete","parts","massive","london","probe","s","backed","cabinet","referendum","labor","threatened","protection","impact","growing","behavior","husband","refused","play","offer","agents","records","cities","affairs","pm","finally","direct","difficult","defend","star","expect","standing","lies","gas","mother","believed","7","serve","newspaper","car","reached","individual","critics","beyond","courts","supporter","progress","avoid","approved","views","chris","ordered","canada","offered","negotiations","continues","2018","believes","abortion","suggested","exchange","statements","reach","test","corporate","strategy","amendment","word","ways","guns","summit","regulations","friend","daughter","joint","macron","counsel","population","activists","maybe","ability","sought","sen","rich","domestic","screen","jerusalem","chicago","killing","god","crimes","19","down","announcement","lack","xi","to","accept","27","growth","body","supported","looks","buy","weekend","related","raise","w","authority","attacked","lose","join","cyber","arrest","21","2011","worse","gay","effect","common","remains","lawsuit","17","kim","cuba","opportunity","considering","showing","spicer","per","credit","period","perhaps","operation","facts","rest","challenge","replace","caught","willing","supporting","22","includes","status","promised","publicly","caused","arms","2008","kids","uk","gone","environmental","block","minority","jr","mexican","establishment","trial","costs","worth","shut","puerto","arab","higher","red","multiple","lawyers","journalists","additional","turkish","michigan","israeli","citing","thinks","mind","jan","breaking","battle","towards","significant","becoming","2010","ohio","stage","opposed","inc","fair","kill","electoral","cover","capture","banks","sense","hollywood","directly","declared","income","coal","putting","particularly","finance","remember","sea","fiscal","green","decide","quite","begin","regime","referring","noted","pick","lie","deep","transgender","socalled","cooperation","approval","appear","migrants","dc","rise","followed","seriously","sept","legislative","eastern","beijing","vladimir","steve","seem","regarding","oct","alliance","rival","ally","accusations","tough","break","blame","necessary","jeff","racism","iranian","propaganda","winning","revealed","association","mostly","communities","at","tells","helping","ended","briefing","upon","afghanistan","28","murder","subject","responsibility","aimed","yemen","reporting","site","trust","ukraine","meetings","launched","joined","language","26","sex","manager","deals","couple","amid","bannon","accounts","bureau","price","moving","facing","embassy","discussed","investigating","de","lying","wikileaks","soldiers","homeland","communications","classified","mueller","guilty","professor","scheduled","reasons","ran","infrastructure","follow","goal","–","trump’s","russians","aides","angry","acting","experience","largely","hopes","available","appeals","hurt","required","powers","separate","meant","version","positions","nbc","tensions","strike","controversial","appeal","23","emergency","estate","bid","constitutional","alabama","female","carry","allowing","approach","warning","various","billionaire","libya","ruled","hannity","broke","rightwing","rejected","steps","iowa","supposed","stated","resolution","paying","light","average","scott","damage","shared","bangladesh","sales","positive","conversation","bomb","pyongyang","pointed","abc","investigations","throughout","pushed","literally","lebanon","doubt","decisions","veterans","msnbc","jail","demand","bit","property","felt","condition","aide","explain","solution","leftist","heart","fully","conspiracy","arizona","erdogan","amount","warren","prosecutors","carson","sarah","piece","game","benefits","values","picture","for","born","removed","islam","cast","40","jones","if","treasury","hill","claiming","alone","romney","promise","girl","african","targeted","annual","29","present","figure","airport","borders","asia","familiar","lady","ceo","career","treatment","markets","judges","activities","technology","mission","gives","fall","spain","played","kremlin","focused","totally","faced","written","voice","reduce","pentagon","designed","changed","are","australia","argued","2009","works","moved","hacking","dropped","increased","suspected","stories","victim","identified","biden","beginning","opponents","happy","60","surprise","housing","addition","seat","collusion","zone","partner","brown","religion","conditions","document","destroy","ben","server","restrictions","humanitarian","compared","with","resources","planning","losing","hotel","conduct","closed","cited","loss","bringing","faces","admitted","playing","martin","ad","save","study","highly","carried","rico","hospital","inauguration","featured","territory","internal","decade","unless","stopped","sort","bloc","please","nine","marriage","starting","possibility","partners","institute","thats","require","bills","age","africa","activist","investors","particular","names","disaster","audience","militant","matters","dozens","brussels","discussion","analysis","vietnam","systems","requests","possibly","31","kushner","thanks","ongoing","minutes","drew","campus","none","allegedly","eric","basis","province","defeat","but","too","thank","islamist","2017realdonaldtrump","streets","secure","receive","note","judicial","he","benefit","specific","paper","asylum","whatever","negative","hell","detained","scene","rape","pushing","clean","racial","offensive","miles","confirmation","behalf","hurricane","denies","affordable","prosecutor","opened","entering","built","judiciary","intended","involvement","illegally","congressman","christmas","reforms","prepared","parenthood","attend","testimony","sometimes","progressive","frontrunner","backing","drive","worried","park","liberals","sheriff","date","watching","payments","orders","explained","reportedly","remove","politically","delegates","dec","agent","abuse","stance","seemed","kept","field","failure","campaigns","mattis","wait","ethnic","boost","assad","palestinian","jim","correct","camp","arrived","drop","chair","capitol","conway","venezuela","sitting","prior","nobody","greater","eventually","door","prices","numerous","wisconsin","thinking","prove","communist","resignation","signs","cash","assembly","vowed","missiles","listen","epa","check","levels","associated","jersey","illinois","attempts","immediate","conducted","advance","training","taiwan","highest","extremely","path","opening","ones","ivanka","interference","catalan","ultimately","strikes","players","management","lawmaker","assistance","innocent","dr","benghazi","attempted","tom","detroit","truly","suspect","station","standards","happens","evening","choose","stood","fuel","estimated","boy","blamed","then","spend","seats","resign","keeping","fed","dismissed","confidence","citizen","richard","guard","wounded","veteran","republic","getty","christie","aware","cops","polling","mention","increasingly","blocked","sweden","limit","investigators","easy","civilians","wearing","platform","natural","treated","happening","attacking","administrations","road","injured","coup","aliens","sick","diplomats","before","unlikely","shown","heads","commitment","code","wealthy","search","raising","lines","institutions","contact","club","ballistic","soros","fighters","schumer","actual","vehicle","linked","lee","appointed","strongly","visa","places","neither","manafort","proof","pennsylvania","flint","abe","serving","providing","otherwise","oh","michelle","himself","antitrump","alternative","donors","broadcast","banned","waiting","sending","retired","looked","dialogue","be","production","japanese","grand","floor","film","carrying","ballot","activity","strategic","relief","potentially","posts","culture","attended","rates","products","pakistan","limited","learned","girls","committees","appearance","navy","minimum","21wire","obvious","businessman","tehran","catalonia","screenshot","prominent","links","investigate","gender","unclear","successful","proposals","homes","fine","failing","sell","praised","ethics","discrimination","consequences","temporary","harassment","crackdown","youtube","seeing","medicaid","immigrant","graham","difference","convicted","standard","session","ross","hezbollah","35","st","simple","prince","overseas","heavily","stupid","spread","presence","waters","surveillance","its","hampshire","wage","supports","oregon","magazine","involving","interior","firms","firing","drugs","controversy","patrick","ireland","hall","abroad","launch","hour","recognize","taxpayers","draft","projects","environment","egypt","science","golf","funded","chancellor","oppose","dispute","challenges","qatar","promote","pledged","mitch","fans","definitely","chuck","christians","trillion","range","netanyahu","meddling","fell","deeply","about","smith","reaction","ministers","wonder","setting","sector"],"legendgroup":"","marker":{"color":"#636efa","size":[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],"sizemode":"area","sizeref":0.1111111111111111,"symbol":"circle"},"mode":"markers","name":"","showlegend":false,"x":[0.45899117,-3.2541182,11.903173,-7.6620383,13.215361,-1.0149834,-0.70060897,-1.7047434,-6.576754,3.0331829,0.50841755,-1.6578047,6.079217,-3.5414407,-1.8230176,3.8104947,5.54064,-15.188663,6.5072446,0.8347877,1.6617215,0.059295833,0.41204783,-11.480675,1.9688354,-8.058938,5.316667,2.8121295,3.6672058,-3.4063213,1.3795851,1.5903292,-22.72453,5.986942,-11.76199,3.4867682,1.7118161,3.8791537,2.4621873,1.8471016,1.875502,-0.89378476,-0.38215128,4.2084064,-4.4738827,6.2248473,5.211221,-3.8747962,-0.31151095,-4.9425135,-5.0431223,1.5310861,0.088923395,-11.854207,-6.731533,1.237078,10.069398,-4.3743525,3.097706,6.249975,7.8257885,4.600617,9.294983,5.380866,-0.0010651052,1.3162103,1.7274199,-14.781378,-0.48065457,34.119152,-9.306746,2.4955456,-4.580676,2.5807447,-0.9555063,-5.663638,2.5188694,-1.9458325,3.3386939,-1.8569984,2.6656864,-3.2645345,1.1513386,-1.4166021,7.349533,2.4364653,-6.174213,1.7696116,-4.536594,6.9215007,-3.3019264,2.118058,-4.533375,-1.8836703,-2.3667502,-0.95689833,5.1841006,-2.5379531,13.1575165,1.3921399,-4.481617,12.216606,-3.797332,1.3397443,-3.988238,-3.5048149,1.8881269,13.797404,3.138894,-9.107017,13.381254,0.3946454,12.131452,-2.4374878,-2.202929,12.212903,-5.978796,6.2787194,3.70621,-10.944525,3.3461971,-8.502568,11.492237,2.0713851,-0.7707262,-3.1986604,1.5549873,4.9020143,2.4486861,3.282574,-41.8919,1.7304559,4.056081,6.8517375,-4.5042315,3.7828608,4.7228456,-3.9038808,0.8555541,-4.063236,1.6773275,-0.0010759532,-4.2745495,2.35769,1.1187773,-8.316269,-0.79769886,-2.4906123,-1.3553324,1.9412194,-0.8234627,-2.9565048,0.83299553,-5.742881,-1.4453316,2.4042037,-0.9127339,-3.376534,-11.754198,1.9001145,0.22837675,2.4343936,-4.2067304,-2.0328112,3.7248302,-1.0802666,-6.385317,3.3618388,-7.3274884,12.510622,2.2727752,-3.1329494,2.79023,0.35645774,4.8613424,3.4820652,2.6298983,-2.3634746,-1.1422349,0.52610093,-9.271118,2.84366,-0.3871384,-0.588205,3.5874865,3.8364723,-5.3121133,-2.7678852,-13.432764,11.211779,-0.68827224,-0.88767827,-0.4611868,3.4085147,-7.6551375,-2.042015,-0.9475212,8.59777,-1.5456492,-1.0677736,-0.027004212,2.4354088,-1.2732669,-10.124986,1.3369591,1.1127887,-3.7866032,0.71427643,0.2886568,2.5671082,1.2014636,-8.042577,1.0780867,-6.0340734,9.440793,1.3747734,-1.5475434,4.431852,-3.796952,-10.436622,-11.218626,-0.2566776,1.7556155,-6.285249,1.3587596,4.212321,-12.354819,-26.483755,-1.0514412,1.9314911,7.017051,0.06938982,-6.268542,-2.5894864,1.2419711,-1.428142,-2.3865108,0.9230264,9.543822,7.4216228,0.56107795,-5.031369,-1.5722647,-3.8786156,-1.8011374,-9.64606,6.4858685,2.8764892,1.2698699,-6.743603,-2.130428,-3.6473157,-0.1737096,2.5576546,-4.4207497,-2.7823224,11.147109,3.731815,-4.1863728,-2.5156972,-0.21553448,-0.42461154,-3.425954,3.2356398,-0.86809516,-7.009083,0.82789195,15.277555,-1.550826,-5.196859,1.4261546,-4.0104604,3.9884698,-7.973909,-7.9735904,-1.9490821,9.477077,13.237862,-6.2384005,-1.9979875,-2.7067022,3.108868,-2.0083144,-2.2745216,1.6884817,-4.13141,3.8815582,-3.8867433,-9.22859,0.6527619,-4.7695036,-4.531073,2.357927,6.7858744,-0.8679985,-5.2451262,5.8287754,2.9373205,2.5754766,7.885534,13.1442585,5.46889,8.325751,-1.1493903,-6.5123224,1.3686439,-6.8394804,0.07295984,1.7278193,6.046228,7.39719,0.97400093,-4.5904393,3.2523634,-0.67163694,-5.000539,2.7749562,3.0802307,-2.6110787,0.9390058,4.7075787,-0.59554076,-1.8216376,-1.6761935,-1.0400467,-29.11137,0.1940127,-3.2179372,-0.12371847,2.7090852,-4.8335886,-0.8711128,-4.3917584,5.0737605,-2.2433412,-1.0796496,-6.040649,-3.601909,-1.7836459,0.76459455,-1.7657924,0.53881526,-2.370376,-6.177287,-1.0015285,-2.1428418,4.0623126,-3.3081043,2.5208924,-3.4522965,5.565173,4.511226,-2.9132662,8.923176,-6.2555647,2.2161267,1.578378,1.8374594,-1.0829792,-0.6615323,-5.799761,-3.5345097,-2.220605,-1.8627975,1.0000706,-1.0169398,-5.398842,-2.5508854,2.4033725,-0.5683105,2.0745826,-0.050582588,4.5058756,1.6943408,-4.6718035,-0.4763153,-3.5534103,3.7453723,1.8815114,-6.591026,-1.9249244,-1.4275175,-0.5317961,-9.472677,-0.7402278,5.914768,2.8991847,-6.393088,0.52976525,2.2656627,-0.5106462,0.9708946,3.0957887,1.7607005,7.4675913,-0.256685,-1.0689293,-3.1433375,19.936132,0.23127928,-7.257072,-0.012449175,4.5618343,6.6675277,3.8010457,-5.1256347,-0.82681966,1.569857,2.7999387,2.6571758,0.54507506,-2.677798,1.3939186,-7.9680247,5.1700373,4.744205,5.6433444,2.8279607,2.697667,-6.101061,3.0341747,-13.231247,-1.6555433,-2.0565474,4.013439,-5.1113663,6.470718,6.4489627,-1.4504201,1.4401311,0.6380098,-1.2819673,-10.087462,7.070481,-3.7468364,1.5449679,-0.07116786,0.623505,-3.380263,-0.79978657,-1.0550473,9.535574,2.1278157,-0.4457492,-4.5056334,0.5133553,-0.32990268,-4.581386,-7.3500805,6.8743234,-5.8044214,0.63389134,-7.193261,-2.8759005,-4.8286505,8.38668,5.539179,4.252059,-5.036977,-5.772699,0.16574037,-1.9833851,-10.548795,1.4301946,4.111349,2.0856845,-2.7992957,-1.9300377,-0.85307515,4.1787157,1.1728077,-5.211178,-0.9730607,-1.44182,-0.77773,9.445259,-1.6601958,-1.7964156,-2.852803,0.018520832,3.807791,-3.3775287,-5.450187,6.5824685,1.6335192,-0.02036643,-4.681208,0.39164138,5.118254,10.166855,-3.3972263,1.7606012,-0.63318527,-1.6118059,3.6457179,1.0225003,0.50868845,-5.011664,3.517686,-3.0756946,-9.159615,-3.0256464,5.7200003,2.9543645,-2.0337381,-14.480161,5.3251595,4.6012206,1.643597,1.0974165,-7.883859,9.116054,2.131688,6.0007515,0.39730465,-5.765533,4.249449,-2.709015,-4.21199,13.688596,5.196116,1.0982516,-0.9483775,1.7922153,3.3689425,-4.3077817,-4.438467,2.8039067,12.585306,-5.927306,-6.6675196,4.2197156,0.080738634,-3.2021577,-5.2019634,-4.6781096,4.273662,-2.4733312,-1.7195165,-0.3667598,0.4469076,9.941461,-2.4684243,-7.005092,-5.597324,-2.2957876,2.6720078,-2.7240965,3.3812551,-0.23888698,6.542596,0.1779162,2.2653584,4.8515725,1.5547737,1.7782699,-0.0074148774,-3.696328,-9.119923,-4.946749,0.5189249,-0.6276579,4.127165,0.57916135,-2.535903,2.1729414,-0.12991497,-3.749791,-2.9915888,-2.5590076,3.111612,-5.1179714,7.430868,-3.2310925,-3.169934,-1.4021349,3.2514865,-5.590661,2.5767088,-10.957749,4.949774,2.7101789,2.1784334,-3.8767688,-1.9302156,2.8487356,0.62309515,-1.0898114,-5.718753,1.2614421,16.270058,-5.2763305,1.1808563,4.788252,-4.34866,-1.9475162,-4.968089,10.597423,1.8852173,0.9572439,-0.6429806,-5.32869,2.6085322,2.2547328,1.5953265,-1.5509497,2.9555964,3.5294566,-6.3031,-2.339036,-9.72498,-1.5331907,-4.9449096,-6.6348906,-10.727493,-6.0576034,-7.9941783,-6.4788904,-6.217949,-4.353556,-2.8511784,5.748753,2.7121272,4.391925,-4.7189403,3.9050443,-3.5716422,7.697684,-8.18341,-8.865093,0.06943637,0.6160082,-4.585209,8.668374,0.15964562,6.1976104,-7.343544,2.9804513,1.8345665,-2.723835,2.2924702,3.2552795,-9.2186,-5.368595,-0.06488511,-4.315011,1.2224643,17.501755,-1.3692428,4.5579834,2.234793,8.492272,1.0290562,4.762766,0.33656716,-5.893363,4.0225534,-2.5116904,-7.8921533,2.571264,3.2397487,-3.2628052,0.7566434,6.216144,-3.0819092,1.7305506,0.9072573,-1.5988941,1.8870019,4.605291,0.14019409,-3.1360195,0.8857015,0.17468423,0.15908876,4.1642528,-7.300621,3.9569302,4.8512273,2.3095136,-1.8343751,3.7816677,-10.804824,0.315616,-6.8082333,5.877273,6.8025317,-3.10797,-1.3848337,-0.44219998,2.3291965,1.1857787,-2.0700123,-6.8675632,2.3373828,0.68864846,6.093478,4.044138,-3.3801484,-2.276657,3.0133862,1.8665513,-4.946266,2.0044634,-3.8682015,-0.09472993,-1.3039604,-1.8496139,6.525928,2.368642,-8.260784,5.577753,-4.1597137,3.9186134,-0.80131507,-1.2375307,-2.0121353,-0.90312874,-3.2499483,-1.2933459,3.0315263,-1.5532048,1.1497003,4.2521744,1.2487864,5.2209477,3.1576602,-3.768613,-4.7950864,2.9743638,3.654913,5.962682,1.1165968,-9.40175,2.3313186,-8.593797,2.3738,-2.353233,-0.82889545,3.7772794,-5.1634383,5.5124235,-9.984238,0.9499688,-7.20485,6.295422,-5.510924,12.122031,-2.2856445,6.837274,1.3392495,-4.5315228,2.8945556,3.0021472,4.952516,3.8829055,2.40359,-5.237403,0.019894153,-10.124465,-1.3596749,-3.6227162,6.6715083,-5.168838,-0.33724645,-2.5562198,-1.7372265,0.52611953,-2.8601284,3.4958432,3.4021027,1.991427,-0.1966798,-3.4796047,-7.68652,-10.820377,9.307366,-5.303109,1.1933103,-3.1501467,1.9027172,-5.1978664,-3.7635963,2.5490851,-1.627578,-13.161299,2.1248546,0.7600013,-2.2565327,-0.8504245,-1.1565111,-4.015922,-0.1362383,-3.4515936,2.1445994,-2.3994968,-1.3929734,-6.1700997,-0.4778563,2.6790528,-5.7407885,1.5476153,0.91914666,-0.35515305,3.7628422,0.21444097,1.2014502,-1.3590628,-0.84907544,3.5661352,4.42131,3.6944604,-2.4796576,-3.182519,-1.3865061,2.4647112,-3.1952567,-5.1248956,-2.3426814,6.6946716,1.3897316,-0.05829528,-8.600539,5.4101915,-0.335732,0.6871004,-1.686029,0.55086225,4.9183574,-2.7696948,1.7973922,-2.754217,-1.7604237,-1.2741781,-3.3363376,-6.8673544,-1.838834,6.700569,14.12007,3.1990829,-8.541547,0.8112257,5.293324,1.1672181,11.464089,2.0041811,4.1776214,1.7718039,-0.7639979,3.5114243,-2.1880982,11.823918,1.8534669,-1.721111,2.721522,3.6551452,1.4160701,-2.6987207,-0.45259222,-0.7980478,1.2199188,-1.6587524,-4.88976,0.28611672,5.8690243,11.849446,-10.869704,4.0641046,-0.48368052,3.098305,-6.252027,1.9413161,-0.28173092,-0.0274584,2.092448,0.7645775,5.809958,4.727168,-0.14111778,-10.393524,-3.5374985,-2.1329238,-2.6128657,-1.412661,-1.8429887,0.0037126243,-6.9758925,2.3148675,1.5801901,2.566323,-1.3158256,-4.425717,1.1476885,2.9542992,1.5866386,0.22834764,4.1764483,-4.277685,0.45536953,0.42066,2.8223968,6.031906,-4.804351,-1.135297,-0.35193065,-8.280969,-1.578721,-0.36550578,-1.1509829,6.7632775,7.3764863,6.092019,2.555215,-0.70584977,0.32497698,3.12228,-6.104113,-0.16884121,3.4481456,-3.5926025,-2.9051178,-2.7098234,5.427207,2.2520916,-4.591421,-1.8556395,-12.656803,-9.027404,4.6727138,-4.393799,3.9057899,-6.230715,-7.6711955,-0.42977378,1.0021026,-0.14146015,-0.9537095,-2.8314397,4.26778,8.826452,4.1246796,1.5658607,-3.3904285,15.201207,1.9169455,-4.8360834,-2.3463724,4.2004743,-2.5166547,1.5532023,-2.285234,-0.97826517,4.6768274,-4.1511736,-5.463235,0.078748524,-0.055884033,8.314735,0.87088215,0.3541441,-2.2352605,1.0711925,2.413747,-3.09699,6.747799,-1.0287321,4.85584,1.1916707,3.6281455,5.689181,0.0020709038,1.0065881,-0.31003413,1.1312164,1.0075313,0.32958347,-8.173399,2.1733103,1.5531479,0.40649286,2.2657132,3.5251274,2.3153627,-3.8135006,-3.2612998,2.688338,4.379235,-0.8019849,-0.46805188,1.7424175,1.6516067,-0.17742768,3.1512723,-8.01336,0.17290154,-9.9642,2.608763,0.61836874,4.760121,3.905559,0.5286821,1.0217417,0.9375876,-0.7117001,-3.949588,-5.4678445,7.569827,1.9366293,-2.0754766,-0.0950267,-0.5797521,4.3574257,0.76422775,2.8239884,-5.2451677,-5.698137,-0.75844276,2.4272428,-1.52652,6.0094104,-1.6726177,-4.7486873,10.849853,-0.2328395,-12.213331,-2.7128253,-1.8620358,-4.062185,5.447659,-3.7752297,2.092771,0.66877854,2.1989086,-16.22379,-5.945072,-4.2035656,2.4144444,2.8019795,2.3439987,2.6797898,0.063910544,-11.745783,6.8659463,-11.982689,3.1760058,7.866749,2.7817147,-0.81060994,-1.6060452,1.66134,-3.0465763,-6.18803,-2.7294729,-0.00074866414,4.7142406,2.5646458,-0.9715029,-10.076262,-3.9705846,1.7161694,-1.8261027,-1.3212273,-3.5650628,-0.34084764,1.1253597,-1.870642,2.491364,-2.269376,-0.11991486,0.73520625,-12.351244,3.320899,3.2778645,5.0272584,0.02551186,7.0115695,-0.2564653,-0.21796551,4.8836746,2.2403796,-0.11481103,3.5242777,0.6728414,1.3000884,-4.253513,1.4713962,-3.1238766,-3.5999115,-1.0386178,4.7497406,-5.2169905,9.335755,10.557454,-6.533507,1.697658,3.6563773,7.2552466,1.1084203,-4.018387,1.2315396,0.86443496,2.0842314,0.010873377,-0.4191381,-7.3167,-0.8529233,3.8546555,-5.118357,-5.441269,2.7893085,-2.3990746,7.0930395,-8.32485,0.2976634,5.374447,-5.5287547,-0.33375576,-3.045775,-2.8973749,-8.985969,3.683692,-0.3570176,0.44626176,-0.2722024,1.2111782,6.8345323,4.4605002,-0.025532097,-2.9868097,4.411356,0.69663566,2.0745423,-6.7467475,7.512266,-0.02888149,-0.5820948,3.6488357,-5.3750615,1.5443962,5.8480706,-0.33782914,4.3311615,-6.130223,7.9064364,-0.7109581,-2.2684176,1.1553309,1.8481328,7.255168,5.610869,3.6109185,0.69616556,4.381419,-2.4627025,-5.0913234,-0.62190294,-5.8574843,4.760615,1.6307358,-3.3609846,-1.3433921,6.916479,12.1075945,1.0296705,-0.89132774,3.1553257,0.1393027,-0.54216635,7.1133556,-8.174037,-4.0754538,0.043301046,-8.132334,2.995943,-2.452863,2.7481098,-1.9166472,6.256595,0.1352967,1.0674124,-3.62058,0.27310348,9.758163,2.6278782,0.2664442,-1.0490096,3.6236017,4.870902,0.76608557,-0.9377775,0.78910136,-0.0053065717,-0.09181914,2.8778827,-2.657528,2.6114094,-1.9517238,-1.3847029,0.81845486,3.9187753,3.461169,-0.13674894,0.21987398,-5.654234,-0.0252375,-1.3983803,0.153956,5.822233,1.6798792,-0.531242,0.39794436,6.294646,-0.3341168,-0.79160404,-2.6727817,-3.814801,-2.3932953,-0.10345927,4.216412,-2.0664353,0.73554903,-3.246471,-6.304943,4.7302723,1.4940157,-7.161229,-3.247616,-4.2584453,0.6774018,0.037286997,0.45377645,-3.4634335,-5.4542627,-1.5353336,-0.7522361,-0.6557729,-7.35489,-0.7922703,-4.255215,2.3565798,1.1557001,-0.07251045,-1.3798513,1.1992254,-3.9679782,8.792096,2.2170858,-1.266564,-4.1364117,4.6996536,1.9242464,1.5233054,-0.37437245,-5.4189796,4.908127,1.4182185,4.63606,9.548169,-5.725755,0.12281674,6.9799604,-7.8360047,-3.3495424,6.6562977,-18.891737,1.816973,-0.23522225,1.3759147,-4.4464846,-0.76345503,0.857065,3.5034182,-0.9666985,3.530951,-0.8909764,-4.8647466,-0.7340622,-5.6113605,-3.880812,4.3115687,1.909679,-9.548258,-4.092443,0.99344647,2.0921922,1.3456535,-5.088191,0.99633884,5.4783626,-2.9369488,7.9447417,6.3176775,1.9216601,-3.250141,-2.464751,-2.1546636,-6.1797276,4.617316,-0.51129305,1.4088389,-9.393284,-3.357143,1.6725886,1.1035867,4.7820396,-0.4279838,0.83742815,0.4409198,-9.049023,0.5203795,1.5152296,-2.2313354,5.5194287,6.3128457,5.495062,9.128829,1.1737374,-5.2230344,-4.178816,-7.0115633,6.796894,5.874888,10.042164,4.350573,5.8675513,2.8283668,-1.6380167,-6.1510005,0.44480473,-6.204149,-6.305175,-1.0506994,-3.8514936,-1.4688993,-8.919843,3.6491067,-0.34599707,0.009427965,-3.2556372,-3.2024002,-3.8969986,0.054429382,2.8977606,-3.6502287,4.6829176,2.146593,1.890678,0.772064,5.469901,5.078736,7.732943,-1.1497799,-2.1044247,1.1246756,8.958208,5.699479,0.754707,-0.014772981,0.022632033,-1.3329463,-2.0674357,-1.1817883,3.0385854,-1.401705,9.390663,-1.0613278,8.322242,3.0965,1.5174162,-1.2866931,-1.3111774,-4.0144897,3.1610515,0.9848248,1.9195182,-6.7446218,-5.837322,4.3654385,-0.7319778,6.463179,-0.9122435,-4.029226,3.1826909,-4.442579,-2.1978369,-4.3890285,-2.197332,0.84453464,-1.5378711,1.6217328,-4.371127,-23.044054,-3.5355904,2.5445004,-5.9319735,-1.3847355,1.1643267,3.4528742,8.285,2.7174,3.7876446,3.0270932,-2.8214226,-0.91135025,2.513079,-0.7562481,2.5476477,0.73530984,-1.5179149,5.938539,0.59816134,-5.1015024,3.254169,-1.2516434,3.4469411,-0.9405885,6.710773,-1.367689,0.4206199,-5.5474105,-2.8641195,-3.395833,2.7358942,-4.0860853,-0.9388701,2.8139832,1.8699061,2.7247174,-7.4119754,-2.0123172,-4.762922,0.5971205,4.490989,-0.22850373,-2.9154859,-4.5473547,-0.2914516,-5.847989,0.8356516,-2.2132516,-2.4369304,3.1525073,0.7603688,11.377824,2.6669104,3.069802,-0.8815329,6.0553055,1.2578018,-2.4304194,-2.8036788,1.1073252,-2.9654143,-0.5009439,-9.52763,9.210194,1.4822667,0.59966314,-2.1515472,-4.39909,-1.1187232,-2.2845607,2.3214245,-1.0801928,2.050755,-2.0295203,7.3854423,-3.9816005,1.7556896,-8.009014,1.1822556,4.9054856,-7.5184274,-1.3710537,6.696622,-4.0259314,-5.9992514,8.544559,-5.167056,-3.3676507,-3.6351445,0.13534456,-2.273493,3.4859772,-5.341707,2.0029542,-0.6030487,-5.4427423,2.1440663,0.3584624,-1.011716,-0.7036772,9.79593,5.2914147,-6.2665234,-6.273704,-1.26161,-3.0028973,-0.23293027,-4.9287863,8.069352,-1.3873671,3.4502037,-1.9509325,-2.3190897,-2.3029146,3.8541918,-2.9765677,5.031568,1.7706139,-4.899655,-4.221072,-1.6381907,2.841874,5.803105,6.3454237,0.60265815,2.4402857,3.8285248,-4.8364363,-0.22884187,10.218945,0.36782157,8.093232,-0.2738894,-2.8517556,2.3264627,-0.8054888,-0.49003395,4.4430995,0.6305401,-1.4694862,-1.1709832,-4.4020987,9.537485,-1.8678887,-1.2306471,2.3859277,2.5924141,-1.6001163,-1.6454182,-0.8905935,9.137129,0.2434386,-5.0379252,-1.2518382,-5.4255867,-2.6101737,6.9209523,-0.30489752,-0.06610784,-5.091544,-1.9618819,-0.23956612,0.95706844,-0.00808689,0.53496695,-0.14173701,-5.489619,1.3984028,2.4030285,4.6202445,-11.132792,-4.5601387,-1.4486222,4.9532037,4.6912255,0.66582775,-0.169022,-1.0672818,-0.48817483,-2.7144303,-1.5351763,1.0607712,4.6273103,3.8202438,-2.9100163,-4.819357,4.435266,-3.8102462,-2.4179232,-1.9122474,-5.0735755,-3.402807,-1.5041275,-2.1064732,4.427076,5.606632,3.6495461,-3.1750176,-1.8275213,1.2661588,1.9954451,3.9193044,-4.011088,0.22847159,-3.22122,4.5120316,-7.0930576,2.7280207,3.5719447,0.9877782,-1.7418885,1.4595997,-1.3602597,13.22408,1.72968,2.7635553,3.9679732,7.637854,0.31165186,3.794571,-2.9262712,2.8035915,-3.8539755,0.3725518,7.919468,-1.1888694,6.059315,4.9156704,-1.2225032,-3.0406215,3.3252995,0.40992293,2.3502483,-4.329584,4.231184,-1.7184956,-6.2377744,-1.4813522,-1.709722,2.735818,-8.79836,-0.5137377,-7.6358037,-1.4308994,2.5887504,5.542143,1.9049563,5.1665444,-0.51940036,-0.07399598,3.920876,-2.4825428,2.9199967,1.3697151,3.7118943,-3.0840185,1.5303166,4.294506,-1.6156089,1.185428,-3.4516094,1.3390044,-2.335322,-1.2265238,-7.486233,3.8855872,-2.2308667,-2.549862,-2.2056854,-1.0286446,-1.7056754,-1.8267052,3.3110626,3.1725078,-2.7143407,8.816142,8.096444,-0.31604806,6.2163053,0.21929981,0.10548672,4.137215,1.236351,1.6433085,0.9435369,-0.5558264,-5.894042,-2.51869,8.001686,1.2519801,-5.285136,3.3590717,-0.15820369,2.7193048,-5.37615,2.513689,4.78758,-1.9428988,1.9556979,-3.4379559,-6.5505333,-10.430495,3.0750344,-2.4114888,2.7211702,6.8574166,-6.0518312,-11.970225,-3.0161917,-3.4713683,0.36342567,6.1057673,-3.9403908,1.1624689,3.7863348,0.79574704,1.632116,0.9163637,-2.4954686,0.25306323,6.934093,0.14723802,8.492796,7.7250986,-1.8042479,5.4886208,0.5633348,-1.9990716,0.8764003,-1.8625541,0.9154726,-1.4908018,-4.9624376,-5.84342,7.458079,-2.4165502,0.911283,-1.3395178,1.5106868,0.24438626,0.37342757,2.7935855,-1.6104927,-0.1531941,-1.782012,-5.82424,-3.221592,6.310928,-0.13808128,-5.7231083,1.9779762,2.8122005,-0.2327291,-7.3845534,-1.5920715,-6.1870904,4.506479,-4.2590394,2.6964154,4.4230523,-3.2476795,2.0286825,0.072319716,3.6581762,-2.25554,2.769999,-0.85226643,-0.52584517,5.8575215,2.9549687,0.6911112,-4.5638504,-1.2820125,13.285233,1.2835466,1.7479411,-2.2621267,3.7949307,8.181712,-0.47736308,-4.5921607,-6.4325714,-3.871259,0.5598688,-3.1866615,-5.2090044,-3.9270627,0.83706415,3.6819916,2.8593538,-2.7763722,1.0380388,-5.602307,0.21444045,4.902278,0.6402586,-4.222921,-1.3490894,0.021995664,3.0249531,-0.8620616,3.7492642,0.7271263,0.48395815,1.0146415,2.1870337,-2.0456347,0.67902803,0.86355686,0.19485831,-4.3234024,1.3330219,-7.082848,2.1390746,-0.72590756,-14.093033,0.58071387,0.852419,1.9291373,-2.0267897,-0.4074293,1.9702672,-2.430937,-3.2358797,3.5870953,-2.1306546,-1.9023323,0.44862846,0.28166437,-5.4023485,-3.486082,8.100804,2.1277258,4.322535,6.626913,-10.094279,-4.205234,-2.6678598,0.040049046,1.3092741,1.7288305,2.1750283,-0.6312982,-0.104364425,0.22653951,3.0757244,0.72466207,-2.661674,2.0095387,2.228245,-1.4235812,-2.8506367,-10.113093,3.8372188,-1.7939281,-7.2785387,3.4320745,1.1954156,0.28989768,2.2407546,-0.93153644,-0.81202424,-1.5613968,0.52695847,3.1540284,-4.66805,0.30277058,-3.8168237,4.011839,0.35989502,1.7739682,-1.9950912,-7.353458,0.8961712,-3.9225705,-7.2302265,5.039326,-1.3306175,0.42067075,-0.9680743,-3.8590786,-0.18545637,5.004926,0.3986259,6.261409,0.45941553,3.2783842,7.253512,3.4895275,-3.8858025,-1.2736583,0.32108188,1.4965963,0.15520808,0.48653632,-0.22867635,-1.4249997,1.5933112,1.3459474,0.8394655,4.0016065,3.314857,5.1330957,0.67434525,-5.5361676,-0.9166988,6.1060553,-0.052265137,0.26633704,-0.38539872,-7.9737544,-5.8032346,2.6512575,3.3179529,12.214913,-6.101917,0.83548325,4.784671,0.80977607,1.6889817,1.4945207,-0.15514627,5.0877385,0.7986143,-0.037685424,-0.6544312,-0.19672433,3.5876777,-0.8446964,-0.68396604,-1.7368879,5.4697785,0.26167235,8.556721,-3.6095293,-2.4328222,2.1531734,-5.682862,-1.1492381,-1.8809047,-1.4791025,0.59375364,0.6356536,4.2713284,5.432973,1.221698,0.90848696,-2.7495768,6.3694706,2.2391422,-0.1598858,-6.9204845,1.7435422,-0.7335031,-1.9566255,2.6365254,9.81725,3.0038595,0.008377194,-0.47043756,-8.26158,0.38040543,3.3483913,5.94877,5.4223514,1.0954719,4.717709,-3.1673856,-2.756463,9.225612,-3.1926668,4.2944283,-0.7561865,2.3344097,-2.9759696,-7.0234127,4.649937,1.5803441,0.08062196,9.072637,-0.5380435,-0.33595935,-1.4621061,0.53768873,1.5815588,7.87819,4.5182953,5.208722,1.9118478,-0.7480928,-2.3220675,-1.628089,-3.3131757,-4.314203,-0.65293944,-1.6873636,-0.21851799,6.0559716,-0.06866476,1.3413329,1.3355843,2.2165103,-2.0988727,-4.0463223,3.8295927,-6.5297985,-0.664706,1.703211],"xaxis":"x","y":[-0.36986753,3.4803464,7.233503,3.2430384,-7.4093013,-1.7497642,4.881485,5.713907,5.515035,-0.6950156,-2.1132333,-0.4990908,-4.660724,11.25963,0.37518018,1.4493921,-0.8479697,4.2459893,2.0129957,-0.1823162,3.7917798,1.4693819,-1.5509946,1.602904,2.5563257,4.888668,0.55762124,0.1380005,1.8472649,2.1848176,2.0897243,-3.6331909,7.7499776,1.6028337,-1.0807847,2.4536202,1.7488086,3.8646708,1.2385832,-1.2903609,-4.4381466,3.634195,-2.3408232,-2.6921182,3.7852936,-2.9949012,-3.3068476,3.8336644,2.5664947,1.5263422,1.2201736,0.35096997,0.7560781,0.4690618,3.248109,-2.7144938,0.79044527,2.5689049,-2.815749,-1.902317,-14.276501,-7.18587,-3.552629,1.5273318,-4.28111,-0.94882303,7.864768,2.912235,-2.8108988,7.673892,1.1353955,-1.9280311,3.9443207,1.7733817,0.05410193,1.8448852,-0.48512298,1.4445497,-4.452839,-1.280657,0.44686902,0.03309998,0.6588163,4.164182,-1.8289783,1.8434254,1.2358962,-3.349322,2.9092665,2.5370858,-3.239398,6.377197,2.6973386,-3.8361506,2.8778822,-2.8181295,-2.2099142,0.16325803,2.6738572,1.5022788,2.3193529,-3.2815332,2.4913144,3.3629706,2.741713,0.26344776,0.71033365,3.4471526,0.59934264,0.5793378,5.047752,-1.1439165,2.5358665,3.143929,1.5810407,-3.1398408,0.89778024,-3.7116008,-1.3203652,6.486555,0.46861756,1.4480039,4.599924,-0.9502158,-1.1709936,0.7998021,-0.8896086,-5.421883,-0.99335366,-5.0246096,21.783634,0.07867275,-0.9462023,-2.0121624,2.8172886,-1.3524323,1.3932099,2.2511017,-2.3986757,3.8246207,-0.31743497,-2.9409118,-0.06827842,2.6741548,-2.5113857,0.2600056,1.132007,-1.3879325,0.60898936,2.4656131,3.6180866,0.95525247,-0.6118376,2.8418882,0.1457559,-3.1616707,-0.2774977,-0.68935424,0.80862457,-2.6970093,-3.5488615,0.9152879,-0.26647362,3.327756,0.10014956,-0.44512153,2.0509892,5.9702454,-1.3179839,-0.9583399,-1.10739,1.5254984,3.9164,-3.816412,4.423166,-1.6945848,-3.6187115,-0.0015332401,2.6215074,-0.8614761,-3.3382454,-2.1765654,0.8209109,-2.5426521,0.22622629,-0.021393344,0.1698804,1.9899427,-0.5897673,-5.3175144,1.6260606,1.7882222,-0.09531697,0.057505324,0.16934867,0.62200725,-0.43980408,-1.6879281,-1.2055691,-2.5812562,1.7653947,-0.46884143,1.9040209,2.2790418,1.4548723,-2.9688148,0.70064867,-1.944378,-0.28922564,0.6227516,-1.0796145,0.67423415,0.06544955,1.4397153,0.51875377,-2.1941001,-1.3956041,0.82964844,3.3121252,-1.9261383,0.62135214,-0.44036967,6.575858,-0.034534752,-0.9318511,-4.6195326,4.330494,6.2034073,4.4048166,-1.4857699,-2.9741883,0.4671806,0.838746,1.9884418,0.6638886,1.0368042,0.94956154,-0.22721457,1.3475536,6.3528028,5.1708245,4.2642174,-1.9958274,-0.32135043,-0.30476195,1.026531,1.1108732,6.0565233,0.1907476,-0.4945234,-0.74743235,0.0978369,-0.39121953,-0.4899614,-0.23558794,3.5416124,-1.776865,4.087791,-0.19291002,1.8918427,1.6944094,-2.3563578,2.0796607,0.7810831,0.3553344,2.3222044,-0.6980343,-2.803784,-2.40602,0.38483596,-0.81348324,0.39263368,1.2584633,-0.84651077,-1.7325238,4.0199738,-4.8473153,7.5799737,2.191524,0.2794906,1.055162,-0.886539,1.4409225,0.45392787,-1.1864024,0.6228189,-3.9209313,-0.20096934,-1.5708277,2.875541,5.466736,-2.1037636,-1.5923898,0.7151694,-2.5909514,-0.21449989,-1.8745936,1.1287341,-1.5178078,5.5196524,-2.2272773,-5.304924,-3.0391529,2.990693,1.7631696,0.15916313,3.6331828,-0.5833224,-2.0069587,0.12959464,-5.8957787,0.63085026,0.76184815,-1.8558588,-3.7577088,0.4394076,0.38722998,0.42937928,2.9523215,-1.4124064,2.0158532,1.3201444,0.6166051,-1.9495537,2.0443454,-1.1904746,-1.7294303,-0.052683413,2.6902628,1.6043149,1.5037718,0.05294372,-1.370478,-0.4920997,-0.6979966,-0.87943155,-0.13058409,-1.1943188,1.5626966,-1.25271,-1.1283507,-0.81969154,-1.0169373,0.083863154,-1.3491206,1.018236,-2.5963328,-0.24291016,-0.76412153,-0.9056697,1.0951604,-1.3624406,1.7691576,-1.7500179,-1.5711097,-0.81401104,-1.8344427,-4.3630905,2.6584802,-2.9831378,0.5584149,-4.3014736,1.2311985,-0.31825328,-0.497611,2.9077506,0.06515764,1.8893522,3.0924494,1.6306745,-0.9314451,-0.36529273,-0.7439812,-3.1055403,-1.4616746,-0.060863525,-0.1353524,-2.5000439,-0.6096439,-0.44793242,-2.417711,-3.868042,0.10462685,-1.1736822,0.8233753,-2.5844345,-4.2156577,0.3607964,-0.67617816,0.70025754,0.8848137,-0.9080118,1.8924054,-0.59856033,-1.2702919,0.06206633,0.777096,0.61189383,12.266693,-0.49796933,2.0881112,-1.8531427,1.5280976,4.681708,-1.2511233,-1.7265359,1.8215033,2.4408615,-2.5986404,-0.9395641,2.210893,-2.4311914,0.8642736,0.7607619,1.5018995,-3.8506799,-1.3847178,0.037937626,-0.035926417,0.29072827,-2.5904706,-8.373883,0.55434215,2.2657268,-2.776745,0.065917775,-5.032477,2.9636362,-0.8790766,-2.9158666,-0.50323516,2.5738559,-2.8929904,-0.95987004,0.35479832,2.3393886,1.5627404,-0.97396255,4.7918487,2.734356,-2.7499514,1.1999089,3.5699413,-2.5701559,0.2982902,-1.2019917,0.027885586,-2.3396072,2.590037,-3.8070161,0.85844845,0.7708452,2.4030488,1.2760906,1.3800092,-1.8209014,-0.0058326125,-2.0941133,-0.12285213,-0.6689993,-0.5946367,1.9352571,2.946095,1.3577981,-2.1135736,0.75982225,-1.171159,2.1096094,-1.0305215,0.32305378,-0.4406853,-1.6573874,2.641413,1.0616561,-1.2177448,2.0252464,-4.1323967,-2.4449604,-1.3289618,-5.549298,-0.13868576,1.5256157,-1.7180647,-1.4867246,-0.2747064,0.3628226,-0.7333695,-0.019983187,2.1426022,-0.95768154,0.93162376,-0.9451681,-0.73372126,0.2630204,2.8188174,-1.7523315,1.6436334,1.2885501,-0.04165472,1.3986287,-5.5196595,-3.0693057,-1.793361,-2.6781366,1.2806454,0.16126184,-1.453708,1.4535946,0.15340362,-0.42043692,1.6433107,3.4335968,-3.3434374,-1.1656429,1.4832627,1.7067989,2.865535,-0.47279912,0.59085554,-0.5693264,-1.926534,-2.4713094,1.6572009,-0.068258986,1.0475142,1.4506911,-1.599554,-1.2077718,-0.35514706,-1.5926597,1.4885734,-2.026169,-0.7033008,0.008225188,2.9734542,1.1287631,1.6049775,0.006593138,2.3234305,2.2201662,-4.493474,-0.591344,-4.0895386,1.7904576,-0.07697944,-3.4114518,2.5177548,3.1633523,1.4315462,0.34641963,-0.61122125,-0.90925777,2.7978523,0.68605363,0.23886119,3.3738167,1.1164677,2.7049563,3.0457063,0.3907519,1.3895783,2.7228644,2.6808786,3.2678974,-3.0845232,-0.47987974,0.96016604,3.852901,1.1708342,-0.2684776,-0.8793313,4.031827,0.27777827,1.1361213,1.0354234,1.6316236,0.58449197,-2.8804164,-0.87909496,-1.0929478,6.72604,2.4311793,-2.5976768,-1.0121884,0.6968973,-2.9403808,-2.848442,0.5574725,-1.6023326,-3.5250866,8.282242,1.19461,-2.0348327,-1.1379708,-1.8001952,-3.1671576,-2.4001677,2.198,2.442407,-2.1590948,0.6877105,-0.29251087,-0.72320306,-4.0048027,0.77329785,1.1709311,-1.2684392,-2.3013403,-2.8955262,-0.018198207,2.2085114,0.07572915,2.609158,2.3209786,-0.13313107,5.956275,2.008043,0.30011046,-0.86602306,-0.5867689,-2.2618446,0.22266273,0.14167343,-1.1676784,-2.7885103,0.6324585,-1.3756412,-0.7538741,-2.7713199,1.2261198,0.019164875,-1.0212286,1.3196355,0.5796689,-2.2721896,2.9085586,-2.9861896,1.3161339,-0.008471802,-1.1084987,-0.4819699,-2.4050567,-4.917812,-1.3683503,-0.5943221,-0.38760012,1.3850837,2.9309742,-4.7414007,-0.23417814,0.7384826,1.69375,-0.8098839,1.1614493,1.7315549,-2.5855758,-0.8725765,3.4912324,-4.5923457,0.20874904,-3.1071258,1.9757446,0.75325143,-0.22025776,-2.1003284,-5.9170475,1.2857565,-0.4296612,-0.04042487,-0.049849376,0.50519884,-1.1119213,-0.09500799,-2.8232608,0.627282,-4.86991,-1.4085823,1.6435575,0.4847672,-0.5123177,1.2001543,-0.43976223,-6.6402016,-1.1107771,0.54458517,2.7871706,-0.14047173,1.5906695,0.866605,0.7517041,-4.608818,-2.026899,-0.07019791,0.3209687,-1.3018622,1.2866191,4.6391816,-2.2826147,-0.38992321,1.1788496,-0.8684885,-2.3212712,-2.5569203,0.5637339,-0.42436343,0.44877702,-3.7147453,0.52042866,-1.0753237,2.6582887,4.57031,-1.3058435,0.9591773,-0.19595325,-1.4277928,1.1747425,-2.9898121,0.5266943,-1.8881187,0.18209516,1.0559292,0.12247194,1.2411526,-4.1843023,-2.46252,-1.630194,1.7926437,-1.3608308,-1.1081766,0.5138288,-0.67521626,0.030332342,2.4539745,1.3714551,2.0909686,-6.1611223,-0.38559896,0.6606342,-0.670561,2.0766854,3.619129,-4.168415,3.1787398,-0.31859493,-4.2289524,-0.5100855,-0.20440446,5.4893875,3.0834174,-2.4982224,-0.28418297,0.9013297,-0.55850345,1.4686775,1.248028,1.7263372,0.46960878,0.4201932,0.09612416,2.3737977,1.2619255,0.66901493,1.5257126,0.071719006,1.3151053,1.6288776,2.1978738,1.0645746,-0.32048264,-0.31465167,-1.3959273,2.6974118,-0.6228423,-2.4365532,3.3019357,-10.431139,-0.5061691,-2.5150664,-2.365403,0.8820686,2.1907787,-2.0857706,-1.4510785,-0.50699,0.008774161,0.75427216,0.20904104,1.1698731,-3.2326307,-2.204629,1.0422553,-2.184368,-0.46032983,1.4938031,-1.8194311,-2.7666385,-1.557865,-3.8687818,1.4108253,0.8971419,-1.9684196,-1.0372714,0.95166737,-0.41300666,0.5088824,3.7934403,2.1163561,-0.21021187,1.2382251,3.684364,-1.1527224,2.06593,1.0508325,0.23112898,-2.196085,-0.61970085,1.4863582,0.4646883,2.295865,0.9325232,-0.88385296,-0.2512528,-1.073995,0.27512002,2.70932,1.9101793,1.4220619,-1.0619538,1.1770837,0.15195532,-1.5507672,-1.0924325,0.24056871,2.196326,-0.96496534,0.6504099,-0.86643237,-0.38852555,7.421428,1.9546663,1.4093584,-1.3314188,-1.7079855,-2.3185213,-0.23417693,0.624873,-1.8161191,1.169382,0.6135003,0.9421528,-0.053544387,4.002059,-0.75660634,0.7318381,-1.505894,3.3657134,0.6097078,-0.3839089,-0.0067558736,-0.39824957,3.2471557,0.7694213,0.7356703,-0.055350274,0.28827643,-2.6795876,-7.3985443,0.20509739,1.4003558,1.4340465,0.24641742,0.0044005364,-3.0865786,0.76482314,0.8243602,-0.43831104,2.0727098,-1.0179052,-0.7995422,0.93920046,-0.6255895,-1.9192537,0.13609536,0.07570006,-0.0749481,2.0895848,-1.4547015,0.58844596,-3.911232,0.23701514,-1.0370693,-0.5357354,-0.10811787,1.1522865,1.9548932,-2.4250212,0.09657161,0.14392753,2.2390156,1.123338,-0.45888078,1.3937271,-3.496224,-1.6837022,-2.1305954,0.32415015,-1.3469853,-0.88511294,2.9647472,-3.7763605,-1.9994612,-0.09905216,-0.0054896027,-4.8933654,-2.0018506,-1.1190978,-0.6904863,0.5182084,-2.757023,0.14704372,-1.3243002,0.081034884,-0.8412071,0.65994805,0.66930425,1.0093929,0.77011395,-4.0907245,1.6416874,0.24706586,-3.8501964,2.9673944,1.4562409,0.91536504,0.16759227,-0.31567183,2.5704494,1.1539115,-2.931241,-1.0607729,-0.42387038,-1.1531739,-1.8576455,0.75160205,-1.0802594,0.75578827,0.425658,-2.0208957,-0.41706347,-1.0559616,-1.2614781,-2.1732843,2.5538144,1.2592837,1.8732837,0.72844726,-2.6448863,0.2801574,-1.2987765,-2.3572376,1.4500452,1.6131163,0.45377433,0.7866649,-2.0894072,-1.5836408,0.032100245,1.1260124,0.3298033,4.536962,-2.64607,2.105606,0.25570184,2.560131,2.7348697,0.1049328,0.22029601,1.6999694,-0.31844202,-0.6813952,2.26791,-0.7433313,0.07182692,-0.5305915,1.4179186,1.1459382,3.3411758,2.8668072,-1.6160587,1.1955553,-0.44310844,3.4981005,0.79576665,-0.20403735,0.30721408,2.9777153,-1.388128,-0.98639584,-2.3572245,0.3069231,1.7203037,0.8671791,3.187521,-3.1322317,-1.8265036,0.6351466,2.5932074,0.56872344,-1.2395617,-0.31315643,-1.2132727,3.549051,-1.885734,-1.5896066,1.6378382,-0.19722989,1.4008945,-2.925479,1.9567522,2.0176914,0.25057447,0.08205043,1.356121,2.006271,-0.4564755,-1.1685224,2.6129582,-0.77502805,0.1796058,0.57552296,3.055008,0.56696856,-1.1227117,-6.609928,-1.0130866,-0.8517975,0.38178933,1.6404577,-0.32122633,-0.19674906,-1.0935849,5.1462436,1.8115,-2.6968186,-0.6396944,2.664759,4.055433,-0.010993883,-0.9007077,2.6829998,0.15761556,2.6138282,-0.8001678,-0.9330757,5.2674904,1.1212848,-1.4283595,0.79963666,0.8223625,1.1253046,0.18298943,-2.7478704,0.31859428,0.3950224,-0.31464708,0.28206462,-2.0228896,3.0570505,-1.149782,0.23618244,-0.9230028,0.91825145,0.5719694,-0.213208,-2.2001448,5.1587043,-0.13410556,-2.877157,-0.15427357,1.5749267,-2.5283062,-0.5527546,1.5236824,-1.2961755,-0.89086944,-0.90586925,-2.7663321,1.7598329,-0.059469193,2.1447256,-1.1040725,2.3805158,-4.896117,-3.2728121,-0.7239483,-0.26953954,-2.2067144,-0.6265158,1.5853407,-1.1966181,-1.0198241,-0.14241816,-0.7268599,0.5013129,-2.9661999,1.3435915,-1.0028434,0.0059820563,-3.2465663,1.6241533,-0.10577052,-8.903276,1.5431116,-0.86444795,1.2073743,-1.7843419,2.594027,-2.1451392,0.095661834,1.7898133,-0.22121303,3.0672688,0.7512394,0.8325135,2.1530664,3.4793916,1.9835349,0.46250153,-3.4615252,1.0850823,-0.6505909,-1.1670135,3.1781058,-0.14610355,-0.81121725,0.82670146,-0.8461448,1.2796879,2.003652,0.2224534,-0.124532536,0.35652375,-1.1810336,0.05367352,-0.2700095,1.5226905,-2.4188583,-1.3965268,6.870002,-0.45237893,-1.4694712,-1.9152386,1.01674,1.7245424,1.3796872,1.9573997,1.3390075,-3.767445,-1.329097,0.40393782,0.7718772,1.839074,-0.96452177,-1.3003087,1.4940397,-0.057960898,0.18087156,-0.4783497,2.1971197,-7.374857,-0.6219606,1.5315783,-3.212659,-5.551154,0.51039416,0.403763,2.3003807,0.20829968,-0.96324056,1.97217,1.063189,-0.56922346,-1.4072992,2.7656446,-0.3161382,-3.3048937,-2.4384837,-0.5187225,-0.5225626,-1.1042067,1.5408393,-0.2549445,0.99527043,-0.50285184,0.7131446,-0.9285464,0.49559557,0.5395367,1.2825958,-3.6396234,-3.1924202,-2.1624057,0.39879167,-0.08786776,2.0021486,-1.4499888,0.33494842,0.50929624,1.5802722,-3.2851994,-1.1438469,-0.46667904,-1.7174993,-2.198625,1.6923517,1.387434,-2.1886122,-0.44304463,1.089981,-1.7381265,-0.13751885,0.6871254,-3.2797225,-0.863282,2.1439683,3.2929485,-2.665657,0.12019114,-1.2985067,-1.2415913,-0.72582185,-0.66528034,-1.749637,-0.9068806,-2.4906492,1.5858057,2.61086,-7.8632855,0.32249773,-0.1821277,-3.2033675,-0.63082963,-0.7011076,-3.1045156,-1.2735795,-0.6275588,-0.9905493,-1.6469653,-0.024108127,-3.2182293,-1.4768771,-2.0310555,0.36286068,-2.396242,1.5511464,0.06369083,1.6121408,-1.1819979,-1.0620626,-1.9939986,2.5141065,-0.21318379,0.76390517,1.277579,9.811417,-0.9134194,-1.3569076,0.4535563,-0.7208696,0.2884282,0.61391413,5.241854,-1.250868,0.51142853,-1.3182788,-1.7699425,0.62644345,-0.8871683,-4.6310115,3.7453766,0.084829286,0.39331776,-0.62626547,-0.44067124,2.0692506,-2.0594296,-0.78209704,1.447357,-3.2535675,2.273758,0.43662655,2.3659518,-1.1089362,-2.086201,0.44643706,-2.3052258,0.091422275,2.4511235,-1.1139262,0.5534873,2.5621767,0.79755646,2.1823661,1.4451616,-1.4725558,0.8887723,1.2980835,-2.6441967,-0.28725728,-1.9476134,0.65976,0.14698897,0.85049397,1.8254455,-0.8145708,1.2829926,2.4129944,-0.5661784,-1.1883564,-2.7086785,0.88925356,1.1547372,2.0958061,0.4205047,0.2997406,-0.001829356,-0.49060923,-0.6598377,0.809403,-0.65161747,0.15376283,-2.8504894,0.16995175,2.9061546,-0.35269052,2.6035128,-0.8761484,1.8810645,-3.427618,0.38428384,-0.13889131,0.896962,1.7303389,-2.3169818,-0.46018207,-2.534962,1.499507,0.021672651,1.9953679,0.15292753,-0.1590102,0.8929656,0.9318022,-0.021840721,-0.042000175,2.0769286,1.4831712,-0.00845331,-2.0986674,-2.9317613,1.7249297,1.4368563,-0.06467356,0.8616076,-0.9312317,-0.53633964,4.843996,0.84499913,0.8573819,0.5819239,-0.5704891,-4.8666697,-2.0531368,1.6881609,1.2593877,1.6704075,1.5283542,-0.28198367,-0.0031677783,0.95221156,2.1501436,-0.86941856,-1.3753617,0.19782256,-2.3577282,1.1302606,-0.9094838,-1.9557493,-1.2781838,0.23046462,14.734505,11.167875,-1.0691279,-0.83428085,1.3209009,-2.4437342,0.9800944,0.18147556,-0.16861507,-0.13695931,-1.3091967,0.061129287,-2.3254309,-2.641441,1.4920069,-1.5479765,1.75651,-0.43163043,-0.33555079,-1.8421559,-3.4801428,-5.0355353,-1.8148327,-2.248995,-1.4199451,-0.314136,-3.1952,-0.93678564,-0.6051601,0.6389615,0.31827587,-1.0556785,-0.1988078,0.4209131,-1.2463927,1.5623826,-2.0103126,-0.5014764,0.4923246,1.8760706,0.60185343,1.0403004,-0.07247564,2.215282,-0.55573136,-3.7784402,-2.460022,-1.7481395,-0.7697073,-0.91306007,0.67859274,0.46411073,-0.51581126,1.973158,0.8137818,1.8680652,-1.0050452,0.83275765,-1.3535827,-1.4160323,-1.7638509,1.4983116,-1.5283676,0.4861849,0.09521033,1.05468,-2.245241,-1.0130357,0.34035498,0.56851757,-2.2059362,-1.9028628,1.1489115,-1.214364,-1.0178611,-2.378811,-0.24670595,1.221892,-1.3679898,0.036370948,0.9508137,3.2410119,-0.30758426,-0.99965036,-0.9948709,-1.140642,-0.7187486,0.29256707,0.3268476,3.566893,-0.11887277,3.4169881,-0.96763784,0.79582244,-1.0115516,2.1910279,1.3560269,-2.1442204,2.886363,0.8899943,0.75948876,-0.60454273,6.0412407,-0.61096406,-2.70686,-0.75283176,-0.7067349,-1.9989308,2.3725438,-0.7657202,1.9245781,-1.1105475,-0.9416563,-1.8780134,-4.286759,-0.43127137,-0.4999953,2.0933242,-2.687456,1.0029407,1.0829625,-1.2051398,0.019336686,-0.0065222085,0.8211244,1.4130251,1.1432852,2.0698566,-0.62221676,2.4862614,-0.17972979,0.73930836,1.9650158,-2.8846664,0.4068855,2.5586479,-0.45539832,0.33958858,-0.6169202,0.39675868,-3.571997,-0.9551248,1.9945184,-0.51273006,-1.0526491,-0.419293,0.75779045,2.9300208,2.7679918,-0.33977455,0.7252027,-1.8433163,-1.3639148,1.3261092,1.7451018,0.9689067,-4.081212,-0.5752901,2.1514473,2.562951,-0.23081851,-0.1705183,-0.54917926,-0.8573539,-1.620708,2.0687606,-2.5231066,-1.7456597,-2.1038976,1.1702976,-1.2870367,0.22913267,-1.8098767,2.8784783,0.28079832,1.6177952,-0.6781158,0.7516229,0.15159898,-1.5890089,-0.44712818,0.2248828,0.3403868,-1.36115,2.17564,0.6681223,-0.085659675,-1.0883842,-0.070479915,-0.5308554,0.12054981,-3.2018297,-0.64325196,-0.4983862,0.91222626,-0.6308665,2.8829157,-2.5525084,1.7501694,0.5617395,-1.3687611,-1.817478,-1.0702236,2.291836,-2.3002598,1.2223773,-3.016393,1.2478633,-2.8045487,-0.28089064,0.55106825,0.30707532,-0.79167926,-0.11751924,1.0658813,8.047481,1.1889207,1.8371876,4.763288,3.718121,0.5013448,0.24250321,-3.198715,-1.897812,0.41256046,1.9031903,0.7164445,-0.1246496,-0.09063192,-0.22856125,-1.0573931,-1.8079163,-3.3681028,0.26617545,0.19901462,-1.9227289,-0.15321188,-1.9571632,-0.4445005,-1.139415,1.7708753,1.3528638,-1.6888591,-2.2973666,-2.7609668,1.9845437,0.97844046,1.1456121,0.2197301,3.4593863,-2.1966717,0.6019836,-1.4526592,-1.8529335,2.1312544,-0.40921468,-0.48595524,-2.7583055,-3.3065376,4.2811737,-0.8590043,-0.5452656,-0.5606977,-2.9831223,-1.1682968,-0.7498176,1.0760411,-2.6319902,-1.760267,1.286859,-0.20418316,-1.553282,-1.3152847,-1.3806086,2.5966125,0.51354754,-0.9702084,0.5432891,0.6102203,0.6369648,1.3671272,1.1662031,-0.34311172,0.9248094,-0.67893314,-1.5909027,1.4990395,0.7975332,0.17519416,-0.3819756,-0.25912213,-1.8794161,-0.7775249,0.783673,0.019911885,1.8928763,-1.2635245,0.43282098,0.89568216,-1.664323,1.1432436,0.34813476,0.10169615,-2.0582557,0.12785734,1.5894797,-2.003003,-0.8499999,-1.5599502,-4.3797045,-0.28432918,-1.3926629,0.06489618,-1.4913687,0.4984985,-0.8422093,-0.28789666,-0.06318727,-0.5899339,-0.34115013,0.45576626,-0.25038132,0.13980685,0.68187743,2.5110645,-1.4607538,-1.3018665,-1.2162638,1.079876,-1.8053956,-2.2537081,-1.1180034,0.35122055,-0.11209847,-0.0456627,0.6293776,1.9491855,0.7535499,-0.2056061,1.6071937,-1.6061813,-0.25191626,0.6585747,-0.35314703,-1.6505584,0.72273225,-0.2040182,-0.8234546,0.5918944,1.298543,-1.2053456,-2.0267644,-1.2526263,-0.4645272,-2.0467904,-1.1057872,-1.5727032,-1.6843355,0.40714353,-2.3470924,-0.82194513,-2.365155,1.0734622,0.57396275,-1.918406,-0.6491729,-1.1115112,-1.9684187,-0.39255458,0.21099551,0.36755562,2.393016,1.5196513,-0.26565835,-1.704627,0.631988,0.6762018,-1.8962185,-0.92734826,0.36159462,0.6334671,1.0043421,-1.2108195,-1.712281,1.2885041,-2.37178,-0.21655883,-0.43818662,-1.4574066,-1.3793763,-0.025314033,0.6956457,-0.11505621,-0.4574586,-2.0289555,0.7753933,-1.143926,-0.40225866,1.7762444,0.3754028,1.5764492,0.9393583,0.6366476,1.0733099,-0.4722864,0.45231944,-1.3756241,-1.8108972,-2.0393105,0.6849829,0.8705713,-1.6857766,0.28523606,-1.7615523,-5.260438,0.12725411,-0.098979056,-1.255401,1.027156,-0.9414244,-0.48029327,1.2168769,0.7235291,-2.7455761,-1.0324979,2.1299348,-1.7524716,3.68675,-0.41316813,-2.1675253,2.9081376,-0.57360166,-0.018884137,4.2249002,-1.4313831,-0.7160891,1.338601,-1.1910906,1.2715131,-3.7331042,0.6973111,-0.1349932,0.58753204,0.9266663,-2.092008,-1.4194485,-0.49241257,0.6605395,-0.022814244,-1.4379997,1.1186043,-1.2475595,1.1542792,-1.0238104,-1.7255028,-1.0725298,-3.733854,-3.037977,-0.9038371,-0.66770977,0.31633168,1.1552283,-1.5631855,-4.6488614,-2.0000117,-2.0494833,-2.7603464,2.1683335,-1.5259578,0.10677673,-2.9810226,1.654657,-0.025411189,-0.14257106,-1.6338347,4.816371,-1.50712,0.7964398,1.0427226,-1.8379651,2.4261053,0.0673372,0.7607984,2.6656296,1.5042543,1.1272454,-0.26307702,-0.4356422,-0.5765647,0.09588887,-0.039968356,0.8025047,1.8301839,0.70008665,-1.3325374,-0.5413672,-0.64961827,-1.0017059,0.5607106,2.4310572,3.2609627,0.81485766,0.26647365,0.18499921,-2.178157,-1.561998,-2.42208,1.7876024,1.6884265,0.05438669,0.29088444,0.034193233,-4.7320547,-3.1351047,0.3692925,-0.6115818,0.18769597,-3.4406383,-0.03180696,-1.2156291,-0.3717174,2.877025,-1.4886866,0.102028504,0.7093311,-1.2716823,1.2399994,-0.71432745,0.44913912,3.1169991,-1.5543483,-1.543699,-0.5192912,0.5346418,-0.33921006,-0.32451403,-1.0171918,0.13457389,-0.9492453,-1.0540822,-1.4113768,1.4932771,0.055723503,1.0214014,-1.0813799,0.4561391,-0.7552385,-0.38009626,-0.026955307,1.0712044,1.61882,1.8705155,0.6171737,-0.4193038,-2.0736706,-1.2095397,-1.3187591,-0.30939627,5.2931614,0.73916763,2.2370548,-1.0237066,0.38932836,2.2216918,1.2945001,-0.7768925,-0.5286618,-1.2595481,-0.62286544,-1.3842285,2.6299288,0.10731213,-0.08114518,2.0159068,-0.9843119,0.71032786,-2.525494,-1.1708477,0.38832867,0.79254407,1.0587351,-0.8158274,-0.13338202,2.5153334,2.63581,0.31984115,-2.0386186,-0.31179553,1.7646173,-2.2211013,2.1671932,-1.7133656,0.29707015,3.3572228,-3.1037962,-0.43924606,1.4236307,0.0251607,0.17234685,-2.2126455,-1.6746379,2.536968,-1.9098836,2.8020096,0.07768382,-2.0039124,-2.292025,-4.31899,0.33459002,0.5251558],"yaxis":"y","type":"scattergl"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}},"xaxis":{"anchor":"y","domain":[0.0,1.0],"title":{"text":"x0"}},"yaxis":{"anchor":"x","domain":[0.0,1.0],"title":{"text":"x1"}},"legend":{"tracegroupgap":0,"itemsizing":"constant"},"margin":{"t":60}},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('50c21bcc-b241-4957-91ef-fd66dca627b3');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                            </script>        </div>


</div>
</div>
</section>
<section id="analysis-3" class="level4">
<h4 class="anchored" data-anchor-id="analysis-3">Analysis</h4>
<p>These words are all about structure, planning, and organization. “Law” and “Politics” are both about how society is run, dealing with rules, policies, and decisions. “Organization” and “Projects” are about groups or actions focused on reaching specific goals through planning and teamwork. The word “goal” connects everything, since all the other words are about setting and achieving goals, whether it’s in politics, law, organizations, or projects. Their closeness shows they all involve systems or efforts to make things happen, which is why they are similar.</p>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>